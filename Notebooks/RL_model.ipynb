{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011d96ec-9499-4e1b-a9ce-9eaa3dc8cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Numerical computations\n",
    "import gym  # RL environment library\n",
    "from gym import spaces  # Used to define state and action spaces\n",
    "import matplotlib.pyplot as plt  # Used for visualization and plotting\n",
    "import pandas as pd  # Used for handling datasets (e.g., weather data)\n",
    "import random\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20d5abcc-86ea-4cc9-b72c-b92eb9a70078",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    Experience replay buffer to store and sample transitions.\n",
    "    \"\"\"\n",
    "    def __init__(self, capacity=100000):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "        self.capacity = capacity\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add experience to buffer\"\"\"\n",
    "        experience = (state, action, reward, next_state, done)\n",
    "        self.buffer.append(experience)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Randomly sample batch of experiences\"\"\"\n",
    "        # Make sure we don't sample more than buffer size\n",
    "        batch_size = min(batch_size, len(self.buffer))\n",
    "        \n",
    "        # Sample random indices\n",
    "        indices = random.sample(range(len(self.buffer)), batch_size)\n",
    "        \n",
    "        # Get samples\n",
    "        states, actions, rewards, next_states, dones = [], [], [], [], []\n",
    "        for i in indices:\n",
    "            s, a, r, s_, d = self.buffer[i]\n",
    "            states.append(s)\n",
    "            actions.append(a)\n",
    "            rewards.append(r)\n",
    "            next_states.append(s_)\n",
    "            dones.append(d)\n",
    "        \n",
    "        return (\n",
    "            np.array(states), \n",
    "            np.array(actions), \n",
    "            np.array(rewards).reshape(-1, 1), \n",
    "            np.array(next_states),\n",
    "            np.array(dones).reshape(-1, 1)\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return current buffer size\"\"\"\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def is_ready(self, batch_size):\n",
    "        \"\"\"Check if buffer has enough experiences\"\"\"\n",
    "        return len(self) >= batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ff3790-5ddb-4578-8833-75fc7ca0cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridEnergyEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(HybridEnergyEnv, self).__init__()\n",
    "\n",
    "        # Define state and action sizes\n",
    "        self.state_size = 4  # [P_solar, P_wind, Energy demand, Grid price]\n",
    "        self.action_size = 3  # [N_pv, N_wt, P_grid]\n",
    "        self.cost_weight = 0.6\n",
    "        self.co2_weight = 0.4\n",
    "\n",
    "        # Action space bounds\n",
    "        self.action_low = np.array([0, 0, 0])  # Min panels, min turbines, min grid power\n",
    "        self.action_high = np.array([300, 50, 200])  # Max panels, max turbines, max grid power\n",
    "\n",
    "        # Define action and observation spaces\n",
    "        self.action_space = spaces.Box(\n",
    "            low=self.action_low,\n",
    "            high=self.action_high,\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([0, 0, 0, 0]),  # Min values for state\n",
    "            high=np.array([0.4, 20, 200, 0.1]),  # Max values for state\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Emission factors (gCO2/kWh)\n",
    "        self.EF_PV = 50  # Emission factor per solar panel\n",
    "        self.EF_WT = 10  # Emission factor per wind turbine\n",
    "        self.EF_grid = 800  # Emission factor for grid power\n",
    "\n",
    "        # Initialize state\n",
    "        self.current_state = None\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the environment to an initial state.\"\"\"\n",
    "        self.current_state = np.array([0, 0, 1000, 0.1])  # Example initial state\n",
    "        return self.current_state\n",
    "\n",
    "    def calculate_cost(self, action, state):\n",
    "        \"\"\"Calculate the comprehensive cost component of the reward.\n",
    "        \n",
    "        Args:\n",
    "            action (array): Contains [N_pv, N_wt, P_grid] - number of PV panels, \n",
    "                            wind turbines, and grid power in kW\n",
    "            state (array): Contains [P_solar, P_wind, Energy demand, Grid price]\n",
    "        \n",
    "        Returns:\n",
    "            float: Negative cost (reward component)\n",
    "        \"\"\"\n",
    "        # Extract values from action and state\n",
    "        pv_count, wt_count, grid_power = action\n",
    "        p_solar, p_wind, energy_demand, grid_price = state\n",
    "        \n",
    "        # Calculate actual power generation\n",
    "        pv_power_per_panel = 0.4  # kW per panel\n",
    "        wt_power_per_turbine = 20  # kW per turbine\n",
    "        pv_power = pv_count * p_solar  # p_solar is capacity factor\n",
    "        wt_power = wt_count * p_wind  # p_wind is capacity factor\n",
    "        \n",
    "        # Capital costs (one-time costs amortized over lifetime)\n",
    "        pv_capex = 1000  # $ per kW\n",
    "        wt_capex = 1500  # $ per kW\n",
    "        pv_lifetime = 25 * 365 * 24  # hours (25 years)\n",
    "        wt_lifetime = 20 * 365 * 24  # hours (20 years)\n",
    "        \n",
    "        # Amortized capital costs per hour\n",
    "        pv_capital_cost = (pv_count * pv_power_per_panel * pv_capex) / pv_lifetime\n",
    "        wt_capital_cost = (wt_count * wt_power_per_turbine * wt_capex) / wt_lifetime\n",
    "        \n",
    "        # Operation and maintenance costs\n",
    "        pv_om_cost = pv_count * pv_power_per_panel * 0.015  # $0.015 per kW per hour\n",
    "        wt_om_cost = wt_count * wt_power_per_turbine * 0.025  # $0.025 per kW per hour\n",
    "        \n",
    "        # Grid electricity costs (using grid_price from state)\n",
    "        grid_cost = max(0, grid_power) * grid_price  # Only pay for imported power\n",
    "        \n",
    "        # Revenue from excess energy if renewable generation exceeds demand\n",
    "        renewable_generation = pv_power + wt_power\n",
    "        excess_energy = max(0, renewable_generation - energy_demand)\n",
    "        \n",
    "        # Land use costs\n",
    "        pv_land_area = pv_count * 8  # 8 m² per panel\n",
    "        wt_land_area = wt_count * 400  # 400 m² per wind turbine\n",
    "        land_lease_cost = (pv_land_area + wt_land_area) * 0.0001  # $ per m² per hour\n",
    "        \n",
    "        # Total cost calculation\n",
    "        total_cost = (\n",
    "            pv_capital_cost + wt_capital_cost +\n",
    "            pv_om_cost + wt_om_cost +\n",
    "            grid_cost +\n",
    "            land_lease_cost\n",
    "        )\n",
    "        \n",
    "        return -total_cost  # Negative as we want to minimize cost\n",
    "    \n",
    "    def calculate_co2(self, action, state):\n",
    "        \"\"\"Calculate comprehensive CO2 emissions component of the reward.\n",
    "        \n",
    "        Args:\n",
    "            action (array): Contains [N_pv, N_wt, P_grid] - number of PV panels, \n",
    "                            wind turbines, and grid power in kW\n",
    "            state (array): Contains [P_solar, P_wind, Energy demand, Grid price]\n",
    "        \n",
    "        Returns:\n",
    "            float: Negative CO2 emissions (reward component)\n",
    "        \"\"\"\n",
    "        # Extract values from action and state\n",
    "        pv_count, wt_count, grid_power = action\n",
    "        p_solar, p_wind, energy_demand, grid_price = state\n",
    "        \n",
    "        # Calculate actual power generation\n",
    "        pv_power_per_panel = 0.4  # kW per panel\n",
    "        wt_power_per_turbine = 20  # kW per turbine\n",
    "        pv_power = pv_count * pv_power_per_panel * p_solar  # p_solar is capacity factor\n",
    "        wt_power = wt_count * wt_power_per_turbine * p_wind  # p_wind is capacity factor\n",
    "        \n",
    "        # Convert from gCO2/kWh to kgCO2/kWh for consistency\n",
    "        ef_pv = self.EF_PV / 1000  # kg CO2/kWh\n",
    "        ef_wt = self.EF_WT / 1000  # kg CO2/kWh\n",
    "        ef_grid = self.EF_grid / 1000  # kg CO2/kWh\n",
    "        \n",
    "        # Lifecycle emissions from manufacturing and installation\n",
    "        # Amortized over lifetime of equipment\n",
    "        pv_lifetime = 25 * 365 * 24  # hours (25 years)\n",
    "        wt_lifetime = 20 * 365 * 24  # hours (20 years)\n",
    "        pv_lifecycle_co2 = 40  # kg CO2-eq per kW\n",
    "        wt_lifecycle_co2 = 11  # kg CO2-eq per kW\n",
    "        \n",
    "        # Hourly lifecycle emissions\n",
    "        pv_manufacturing_co2 = (pv_count * pv_power_per_panel * pv_lifecycle_co2) / pv_lifetime\n",
    "        wt_manufacturing_co2 = (wt_count * wt_power_per_turbine * wt_lifecycle_co2) / wt_lifetime\n",
    "        \n",
    "        # Operational emissions\n",
    "        pv_op_co2 = pv_power * ef_pv\n",
    "        wt_op_co2 = wt_power * ef_wt\n",
    "        grid_co2 = max(0, grid_power) * ef_grid\n",
    "        \n",
    "        # Maintenance emissions\n",
    "        pv_maintenance_co2 = pv_count * 0.0002  # kg CO2 per panel per hour\n",
    "        wt_maintenance_co2 = wt_count * 0.001  # kg CO2 per turbine per hour\n",
    "        \n",
    "        # Total emissions calculation\n",
    "        total_co2 = (\n",
    "            pv_manufacturing_co2 + wt_manufacturing_co2 +\n",
    "            pv_op_co2 + wt_op_co2 +\n",
    "            pv_maintenance_co2 + wt_maintenance_co2 +\n",
    "            grid_co2 \n",
    "        )\n",
    "        \n",
    "        return -total_co2  # Negative as we want to minimize emissions\n",
    "    \n",
    "    def calculate_reward(self, action, state):\n",
    "        \"\"\"Calculate the combined reward from cost and emissions components.\n",
    "        \n",
    "        Args:\n",
    "            action (array): [N_pv, N_wt, P_grid]\n",
    "            state (array): [P_solar, P_wind, Energy demand, Grid price]\n",
    "            \n",
    "        Returns:\n",
    "            float: Combined reward value\n",
    "        \"\"\"\n",
    "        # Calculate cost and emissions components\n",
    "        cost_component = self.calculate_cost(action, state)\n",
    "        co2_component = self.calculate_co2(action, state)\n",
    "        \n",
    "\n",
    "        \n",
    "        # Calculate combined reward\n",
    "        reward = (self.cost_weight * cost_component) + (self.co2_weight * co2_component)\n",
    "        \n",
    "        # Add penalty for not meeting energy demand\n",
    "        p_solar, p_wind, energy_demand, grid_price = state\n",
    "        pv_count, wt_count, grid_power = action\n",
    "        pv_power_per_panel = 0.4  # kW per panel\n",
    "        wt_power_per_turbine = 20  # kW per turbine\n",
    "        \n",
    "        total_generation = (pv_count * p_solar) + \\\n",
    "                           (wt_count * p_wind) + \\\n",
    "                           grid_power\n",
    "        \n",
    "        if total_generation < energy_demand:\n",
    "            # Penalty for not meeting demand\n",
    "            shortage = energy_demand - total_generation\n",
    "            demand_penalty = -100 * shortage / energy_demand\n",
    "            reward += demand_penalty\n",
    "        \n",
    "        return reward\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Execute one time step in the environment.\"\"\"\n",
    "        # Extract action components\n",
    "        N_pv = int(action[0])  # Number of PV panels (integer)\n",
    "        N_wt = int(action[1])  # Number of wind turbines (integer)\n",
    "        P_grid_action = action[2]  # Grid power (continuous)\n",
    "        \n",
    "        # Extract current state\n",
    "        P_solar, P_wind, energy_demand, grid_price = self.current_state\n",
    "        \n",
    "        # Compute energy generated\n",
    "        pv_power_per_panel = 0.4  # kW per panel (previously 0.2 * 300W = 60W = 0.06kW)\n",
    "        wt_power_per_turbine = 20  # kW per turbine (previously 0.5 * 10000W = 5000W = 5kW)\n",
    "        \n",
    "        P_pv = N_pv * P_solar   \n",
    "        P_wt = N_wt * P_wind \n",
    "        total_renewable_energy = P_pv + P_wt\n",
    "        \n",
    "        # Compute energy deficit and grid usage\n",
    "        energy_deficit = max(0, energy_demand - total_renewable_energy)\n",
    "        grid_power_used = min(P_grid_action, energy_deficit)\n",
    "        \n",
    "        # Calculate cost and CO2 components using our comprehensive models\n",
    "        cost_component = self.calculate_cost(action, self.current_state)\n",
    "        co2_component = self.calculate_co2(action, self.current_state)\n",
    "        \n",
    "\n",
    "        # Compute reward using the weighted components\n",
    "        reward = (self.cost_weight * cost_component) + (self.co2_weight * co2_component)\n",
    "        \n",
    "        # Add penalty for not meeting energy demand\n",
    "        total_generation = total_renewable_energy + grid_power_used\n",
    "        if total_generation < energy_demand:\n",
    "            # Penalty for not meeting demand\n",
    "            shortage = energy_demand - total_generation\n",
    "            demand_penalty = -100 * shortage / energy_demand\n",
    "            reward += demand_penalty\n",
    "        \n",
    "        # Update state with random fluctuations (keeping your original approach)\n",
    "        next_P_solar = np.clip(P_solar + np.random.uniform(-50, 50), 0, 1200)\n",
    "        next_P_wind = np.clip(P_wind + np.random.uniform(-2, 2), 0, 25)\n",
    "        next_state = np.array([\n",
    "            next_P_solar,\n",
    "            next_P_wind,\n",
    "            energy_demand,  # Demand remains fixed\n",
    "            grid_price  # Grid price remains fixed\n",
    "        ])\n",
    "        \n",
    "        self.current_state = next_state\n",
    "        done = False\n",
    "        \n",
    "        # Provide additional info for debugging or monitoring\n",
    "        info = {\n",
    "            'renewable_energy': total_renewable_energy,\n",
    "            'grid_energy': grid_power_used,\n",
    "            'total_energy': total_generation,\n",
    "            'energy_demand': energy_demand,\n",
    "            'cost_component': -cost_component,  # Convert back to positive for reporting\n",
    "            'co2_component': -co2_component,    # Convert back to positive for reporting\n",
    "            'demand_met': total_generation >= energy_demand\n",
    "        }\n",
    "        \n",
    "        return next_state, reward, done, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c9b7097-735c-474c-a1af-8a60a8273e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class EnhancedQAgent:\n",
    "    def __init__(self, env, alpha=0.1, gamma=0.98, epsilon=1.0, epsilon_decay=0.995, min_epsilon=0.05, max_energy=200):\n",
    "        self.env = env\n",
    "        self.max_energy = max_energy\n",
    "        \n",
    "        # Reduce action space dimensionality for better learning\n",
    "        self.n_pv_values = np.arange(0, 301, 10)  # 0 to 300 panels in steps of 10\n",
    "        self.n_wt_values = np.arange(0, 51, 5)    # 0 to 50 turbines in steps of 5\n",
    "        self.p_grid_values = np.arange(0, 201, 20)  # 0 to 200 grid power in steps of 20\n",
    "        \n",
    "        self.action_space_pv = list(self.n_pv_values)\n",
    "        self.action_space_wt = list(self.n_wt_values)\n",
    "        self.action_space_grid = list(self.p_grid_values)\n",
    "        \n",
    "        self.pv_size = len(self.action_space_pv)\n",
    "        self.wt_size = len(self.action_space_wt)\n",
    "        self.grid_size = len(self.action_space_grid)\n",
    "        self.action_count = self.pv_size * self.wt_size * self.grid_size\n",
    "        \n",
    "        # Use a dictionary for sparse Q-table representation\n",
    "        self.q_table = {}\n",
    "        \n",
    "        # Target network implementation\n",
    "        self.target_q_table = {}\n",
    "        self.update_target_counter = 0\n",
    "        self.target_update_frequency = 10  # Update target network every 10 episodes\n",
    "        \n",
    "        # Hyperparameters - improved values\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.min_epsilon = min_epsilon\n",
    "        \n",
    "        # Track visited states for memory optimization\n",
    "        self.visited_states = set()\n",
    "        \n",
    "        # Track metrics separately\n",
    "        self.cost_history = []\n",
    "        self.co2_history = []\n",
    "        self.energy_violation_history = []\n",
    "        \n",
    "    def discretize_state(self, state):\n",
    "        \"\"\"Convert continuous state to a discretized key with appropriate granularity.\"\"\"\n",
    "        # Increase discretization precision for better state representation\n",
    "        return tuple(np.round(state, decimals=2))\n",
    "    \n",
    "    def action_to_idx(self, action):\n",
    "        \"\"\"Convert action tuple to flat index.\"\"\"\n",
    "        pv_idx = self.action_space_pv.index(action[0])\n",
    "        wt_idx = self.action_space_wt.index(action[1])\n",
    "        grid_idx = self.action_space_grid.index(action[2])\n",
    "        return pv_idx * (self.wt_size * self.grid_size) + wt_idx * self.grid_size + grid_idx\n",
    "    \n",
    "    def idx_to_action(self, idx):\n",
    "        \"\"\"Convert flat index to action tuple.\"\"\"\n",
    "        grid_idx = idx % self.grid_size\n",
    "        temp = idx // self.grid_size\n",
    "        wt_idx = temp % self.wt_size\n",
    "        pv_idx = temp // self.wt_size\n",
    "        \n",
    "        return (self.action_space_pv[pv_idx],\n",
    "                self.action_space_wt[wt_idx],\n",
    "                self.action_space_grid[grid_idx])\n",
    "    \n",
    "    def estimate_total_energy(self, action, state):\n",
    "        \"\"\"Estimate the total energy generated by the given action.\"\"\"\n",
    "        pv_count, wt_count, grid_power = action\n",
    "        \n",
    "        pv_power = state[0]  #power factor\n",
    "        wind_power = state[1]  # Wind power factor\n",
    "        \n",
    "        # Simplified energy calculations\n",
    "        pv_energy = pv_count * pv_power\n",
    "        wt_energy = wt_count * wind_power\n",
    "        \n",
    "        total_energy = pv_energy + wt_energy + grid_power\n",
    "        return total_energy\n",
    "        \n",
    "    def get_valid_action(self, action, state):\n",
    "        \"\"\"Adjust the action to ensure total energy doesn't exceed the maximum limit.\"\"\"\n",
    "        pv_count, wt_count, grid_power = action\n",
    "        total_energy = self.estimate_total_energy(action, state)\n",
    "        \n",
    "        if total_energy <= self.max_energy:\n",
    "            return action  # Action is already valid\n",
    "        \n",
    "        # We need to reduce energy - prioritize reducing grid power first\n",
    "        excess_energy = total_energy - self.max_energy\n",
    "        adjusted_grid = max(0, grid_power - excess_energy)\n",
    "        \n",
    "        # Find the closest valid grid power value in our discretized space\n",
    "        adjusted_grid = min(self.action_space_grid, key=lambda x: abs(x - adjusted_grid))\n",
    "        \n",
    "        adjusted_action = (pv_count, wt_count, adjusted_grid)\n",
    "        \n",
    "        # Verify the adjustment worked\n",
    "        if self.estimate_total_energy(adjusted_action, state) > self.max_energy:\n",
    "            # If still over limit, find the most conservative valid action\n",
    "            for g in self.action_space_grid:\n",
    "                test_action = (pv_count, wt_count, g)\n",
    "                if self.estimate_total_energy(test_action, state) <= self.max_energy:\n",
    "                    return test_action\n",
    "            \n",
    "            # If no valid action found with current PV/WT, reduce them\n",
    "            return (0, 0, min(self.action_space_grid, key=lambda x: x if x <= self.max_energy else float('inf')))\n",
    "        \n",
    "        return adjusted_action\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        \"\"\"Epsilon-greedy policy for action selection with energy constraint.\"\"\"\n",
    "        state = self.discretize_state(state)\n",
    "        \n",
    "        # Explore: Randomly sample from action space components\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            pv = random.choice(self.action_space_pv)\n",
    "            wt = random.choice(self.action_space_wt)\n",
    "            grid = random.choice(self.action_space_grid)\n",
    "            action = (pv, wt, grid)\n",
    "            return self.get_valid_action(action, state)  # Ensure action meets energy constraint\n",
    "        \n",
    "        # Exploit: Use the best known action\n",
    "        if state not in self.q_table:\n",
    "            # Initialize on-demand with a single random action\n",
    "            self.q_table[state] = {0: 0.0}\n",
    "            action = self.idx_to_action(0)\n",
    "            return self.get_valid_action(action, state)  # Ensure action meets energy constraint\n",
    "        \n",
    "        # Find best action index\n",
    "        best_idx = max(self.q_table[state], key=self.q_table[state].get)\n",
    "        action = self.idx_to_action(best_idx)\n",
    "        return self.get_valid_action(action, state)  # Ensure action meets energy constraint\n",
    "    \n",
    "    def update_target_network(self):\n",
    "        \"\"\"Update the target network with the current Q-table values.\"\"\"\n",
    "        self.target_q_table = {state: dict(values) for state, values in self.q_table.items()}\n",
    "    \n",
    "    def update_q_table(self, state, action, reward, cost, co2, next_state):\n",
    "        \"\"\"Update Q-table using the Q-learning formula with sparse representation.\"\"\"\n",
    "        state = self.discretize_state(state)\n",
    "        next_state = self.discretize_state(next_state)\n",
    "        \n",
    "        # Convert action to index - handle non-discretized values\n",
    "        try:\n",
    "            pv = min(self.action_space_pv, key=lambda x: abs(x - action[0]))\n",
    "            wt = min(self.action_space_wt, key=lambda x: abs(x - action[1]))\n",
    "            grid = min(self.action_space_grid, key=lambda x: abs(x - action[2]))\n",
    "            mapped_action = (pv, wt, grid)\n",
    "            action_idx = self.action_to_idx(mapped_action)\n",
    "        except ValueError:\n",
    "            # Fallback if conversion fails\n",
    "            action_idx = 0\n",
    "        \n",
    "        # Initialize state entry if new\n",
    "        if state not in self.q_table:\n",
    "            self.q_table[state] = {}\n",
    "        \n",
    "        # Initialize action value if new\n",
    "        if action_idx not in self.q_table[state]:\n",
    "            self.q_table[state][action_idx] = 0.0\n",
    "        \n",
    "        # Add to visited states\n",
    "        self.visited_states.add(state)\n",
    "        \n",
    "        # Find maximum Q-value for next state using target network\n",
    "        if next_state in self.target_q_table and self.target_q_table[next_state]:\n",
    "            best_next_q = max(self.target_q_table[next_state].values())\n",
    "        else:\n",
    "            best_next_q = 0.0\n",
    "        \n",
    "        # Update rule\n",
    "        self.q_table[state][action_idx] += self.alpha * (\n",
    "            reward + self.gamma * best_next_q - self.q_table[state][action_idx]\n",
    "        )\n",
    "        \n",
    "        # Remove near-zero Q-values to save memory\n",
    "        if abs(self.q_table[state][action_idx]) < 1e-6:\n",
    "            del self.q_table[state][action_idx]\n",
    "            # Remove empty state entries\n",
    "            if not self.q_table[state]:\n",
    "                del self.q_table[state]\n",
    "    \n",
    "    def train(self, episodes=2000, max_steps=15000, cost_weight=0.5, co2_weight=0.5):\n",
    "        \"\"\"Train the agent with separate tracking of cost and CO2 metrics.\"\"\"\n",
    "        rewards = []\n",
    "        cost_history = []\n",
    "        co2_history = []\n",
    "        energy_violations = []\n",
    "        \n",
    "        # Initialize target network\n",
    "        self.update_target_network()\n",
    "        \n",
    "        for episode in range(episodes):\n",
    "            state = self.env.reset()\n",
    "            total_reward = 0\n",
    "            episode_violations = 0\n",
    "            episode_cost = 0\n",
    "            episode_co2 = 0\n",
    "            \n",
    "            for step in range(max_steps):\n",
    "                action = self.choose_action(state)\n",
    "                \n",
    "                # Check if original action would violate energy constraint\n",
    "                total_energy = self.estimate_total_energy(action, state)\n",
    "                if total_energy > self.max_energy:\n",
    "                    episode_violations += 1\n",
    "                \n",
    "                # Calculate individual reward components\n",
    "                cost = env.calculate_cost(action, state)\n",
    "                co2 = env.calculate_co2(action, state)\n",
    "                \n",
    "                # Combined reward with weights\n",
    "                reward = (env.cost_weight * cost) + (env.co2_weight * co2)\n",
    "                \n",
    "                # Additional penalty for actions that would exceed energy limit\n",
    "                if total_energy > self.max_energy:\n",
    "                    energy_penalty = -abs(total_energy - self.max_energy) * 0.1  # Scale penalty by excess\n",
    "                    reward += energy_penalty\n",
    "                \n",
    "                next_state, env_reward, done, _ = self.env.step(action)\n",
    "                \n",
    "                # Update Q-table with our calculated reward\n",
    "                self.update_q_table(state, action, reward, cost, co2, next_state)\n",
    "                \n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "                episode_cost += cost\n",
    "                episode_co2 += co2\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "            \n",
    "            # Update target network periodically\n",
    "            self.update_target_counter += 1\n",
    "            if self.update_target_counter % self.target_update_frequency == 0:\n",
    "                self.update_target_network()\n",
    "            \n",
    "            # Decay epsilon faster than before\n",
    "            self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)\n",
    "            \n",
    "            # Record metrics\n",
    "            rewards.append(total_reward)\n",
    "            cost_history.append(episode_cost)\n",
    "            co2_history.append(episode_co2)\n",
    "            energy_violations.append(episode_violations)\n",
    "            \n",
    "            # Print progress less frequently\n",
    "            if episode % 20 == 0:\n",
    "                print(f\"Episode {episode}, Reward: {total_reward:.2f}, Cost: {episode_cost:.2f}, CO2: {episode_co2:.2f}, Violations: {episode_violations}\")\n",
    "        \n",
    "        self.cost_history = cost_history\n",
    "        self.co2_history = co2_history\n",
    "        self.energy_violation_history = energy_violations\n",
    "        \n",
    "        print(f\"Training complete. Final epsilon: {self.epsilon:.4f}\")\n",
    "        print(f\"Final Q-table size: {len(self.q_table)} states\")\n",
    "        \n",
    "        return rewards, cost_history, co2_history, energy_violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97771c8b-5ecd-4403-863a-75fac15778eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(agent, episodes=100, max_steps=5000):\n",
    "    \"\"\"Test the trained agent with separate tracking of cost and CO2 metrics.\"\"\"\n",
    "    # Save exploration rate and set to minimum for testing\n",
    "    original_epsilon = agent.epsilon\n",
    "    agent.epsilon = agent.min_epsilon\n",
    "    \n",
    "    total_rewards = []\n",
    "    cost_values = []\n",
    "    co2_values = []\n",
    "    violations = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state = agent.env.reset()\n",
    "        total_reward = 0\n",
    "        episode_violations = 0\n",
    "        episode_cost = 0\n",
    "        episode_co2 = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            action = agent.choose_action(state)\n",
    "            \n",
    "            # Check for energy violations\n",
    "            total_energy = agent.estimate_total_energy(action, state)\n",
    "            if total_energy > agent.max_energy:\n",
    "                episode_violations += 1\n",
    "            \n",
    "            # Calculate individual metrics\n",
    "            cost = agent.env.calculate_cost(action, state)\n",
    "            co2 = agent.env.calculate_co2(action, state)\n",
    "            \n",
    "            state, env_reward, done, _ = agent.env.step(action)\n",
    "            \n",
    "            # Use our calculated reward\n",
    "            reward = env.cost_weight * cost + env.co2_weight * co2\n",
    "            \n",
    "            total_reward += reward\n",
    "            episode_cost += cost\n",
    "            episode_co2 += co2\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        violations += episode_violations\n",
    "        total_rewards.append(total_reward)\n",
    "        cost_values.append(episode_cost)\n",
    "        co2_values.append(episode_co2)\n",
    "        \n",
    "        if episode % 5 == 0:\n",
    "            print(f\"Test episode {episode}: Reward={total_reward:.2f}, Cost={episode_cost:.2f}, CO2={episode_co2:.2f}, Violations={episode_violations}\")\n",
    "    \n",
    "    # Restore original exploration rate\n",
    "    agent.epsilon = original_epsilon\n",
    "    \n",
    "    print(f\"Testing complete. Average reward: {np.mean(total_rewards):.2f}\")\n",
    "    print(f\"Average cost: {np.mean(cost_values):.2f}, Average CO2: {np.mean(co2_values):.2f}\")\n",
    "    print(f\"Total violations: {violations}\")\n",
    "    \n",
    "    return np.mean(total_rewards), np.mean(cost_values), np.mean(co2_values), violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac1389a2-87e2-4286-8d82-5a3d72a58606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_strategy(env, episodes=200, max_steps=5000, max_energy=200):\n",
    "    \"\"\"Industry standard heuristic-based strategy for energy management.\n",
    "    Uses rule-based decision making with some adaptability.\"\"\"\n",
    "    total_rewards = []\n",
    "    cost_values = []\n",
    "    co2_values = []\n",
    "    violations = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        episode_violations = 0\n",
    "        episode_cost = 0\n",
    "        episode_co2 = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            # Get current state values\n",
    "            pv_factor = state[0]  # Solar power factor\n",
    "            wind_factor = state[1]  # Wind power factor\n",
    "            \n",
    "            # Rule-based decision making based on renewable conditions\n",
    "            # If good renewable conditions, use more renewable sources\n",
    "            if pv_factor > 0.6:  # Good solar conditions\n",
    "                pv_panels = 200  # High solar utilization\n",
    "            elif pv_factor > 0.3:  # Medium solar conditions\n",
    "                pv_panels = 150  # Medium solar utilization\n",
    "            else:  # Poor solar conditions\n",
    "                pv_panels = 50   # Minimal solar utilization\n",
    "            \n",
    "            if wind_factor > 0.7:  # Good wind conditions\n",
    "                wind_turbines = 35  # High wind utilization\n",
    "            elif wind_factor > 0.4:  # Medium wind conditions\n",
    "                wind_turbines = 20  # Medium wind utilization\n",
    "            else:  # Poor wind conditions\n",
    "                wind_turbines = 5   # Minimal wind utilization\n",
    "            \n",
    "            # Calculate expected renewable energy\n",
    "            renewable_energy = (pv_panels * pv_factor) + (wind_turbines * wind_factor)\n",
    "            \n",
    "            # Determine grid power needed to meet demand\n",
    "            # Industry typically aims for ~10% buffer over estimated need\n",
    "            grid_power = max(0, min(1000, (max_energy - renewable_energy) * 1.1))\n",
    "            \n",
    "            # Round to nearest grid power increment\n",
    "            grid_power = round(grid_power / 50) * 50\n",
    "            \n",
    "            # Final action\n",
    "            action = (pv_panels, wind_turbines, grid_power)\n",
    "            \n",
    "            # Check for energy constraint violation\n",
    "            total_energy = pv_panels * pv_factor + wind_turbines * wind_factor + grid_power\n",
    "            if total_energy > max_energy:\n",
    "                # Adjust grid power down\n",
    "                excess = total_energy - max_energy\n",
    "                adjusted_grid = max(0, grid_power - excess)\n",
    "                # Round to nearest increment\n",
    "                adjusted_grid = round(adjusted_grid / 50) * 50\n",
    "                action = (pv_panels, wind_turbines, adjusted_grid)\n",
    "                episode_violations += 1\n",
    "            \n",
    "            # Calculate metrics\n",
    "            cost = env.calculate_cost(action, state)\n",
    "            co2 = env.calculate_co2(action, state)\n",
    "            \n",
    "            # Combined reward\n",
    "            reward = env.cost_weight * cost + env.co2_weight * co2\n",
    "            \n",
    "            state, env_reward, done, _ = env.step(action)\n",
    "            \n",
    "            total_reward += reward\n",
    "            episode_cost += cost\n",
    "            episode_co2 += co2\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        violations += episode_violations\n",
    "        total_rewards.append(total_reward)\n",
    "        cost_values.append(episode_cost)\n",
    "        co2_values.append(episode_co2)\n",
    "    \n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    avg_cost = np.mean(cost_values)\n",
    "    avg_co2 = np.mean(co2_values)\n",
    "    \n",
    "    print(f\"Industry standard strategy. Average reward: {avg_reward:.2f}\")\n",
    "    print(f\"Average cost: {avg_cost:.2f}, Average CO2: {avg_co2:.2f}\")\n",
    "    print(f\"Total violations: {violations}\")\n",
    "    \n",
    "    return avg_reward, avg_cost, avg_co2, violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab30131-e77f-4707-9cfb-7e27a0fe5fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yassine Lahniche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Q-learning agent...\n",
      "Episode 0, Reward: -13573.60, Cost: -6331.32, CO2: -24437.02, Violations: 0\n",
      "Episode 20, Reward: -15739.33, Cost: -8064.18, CO2: -27252.05, Violations: 0\n",
      "Episode 40, Reward: -11749.66, Cost: -6288.95, CO2: -19940.68, Violations: 2\n",
      "Episode 60, Reward: -10599.04, Cost: -5422.62, CO2: -18363.64, Violations: 1\n",
      "Episode 80, Reward: -9532.20, Cost: -4562.75, CO2: -16986.36, Violations: 0\n",
      "Episode 100, Reward: -7504.40, Cost: -3411.99, CO2: -13642.83, Violations: 1\n",
      "Episode 120, Reward: -8789.46, Cost: -4810.26, CO2: -14758.27, Violations: 0\n",
      "Episode 140, Reward: -4383.74, Cost: -2202.38, CO2: -7655.77, Violations: 0\n",
      "Episode 160, Reward: -7688.82, Cost: -4065.41, CO2: -13123.94, Violations: 0\n",
      "Episode 180, Reward: -8311.71, Cost: -4416.63, CO2: -14154.31, Violations: 0\n",
      "Episode 200, Reward: -4273.01, Cost: -2236.16, CO2: -7328.28, Violations: 0\n",
      "Episode 220, Reward: -5450.93, Cost: -2773.72, CO2: -9466.74, Violations: 1\n",
      "Episode 240, Reward: -4328.82, Cost: -2142.35, CO2: -7608.52, Violations: 0\n",
      "Episode 260, Reward: -5948.91, Cost: -3249.08, CO2: -9998.64, Violations: 1\n",
      "Episode 280, Reward: -4843.92, Cost: -2685.94, CO2: -8080.87, Violations: 1\n",
      "Episode 300, Reward: -3557.49, Cost: -1793.95, CO2: -6202.79, Violations: 1\n",
      "Episode 320, Reward: -2647.59, Cost: -1385.77, CO2: -4540.30, Violations: 0\n",
      "Episode 340, Reward: -3473.94, Cost: -1839.30, CO2: -5925.89, Violations: 0\n",
      "Episode 360, Reward: -3388.48, Cost: -1977.87, CO2: -5504.39, Violations: 0\n",
      "Episode 380, Reward: -4298.61, Cost: -2623.55, CO2: -6811.18, Violations: 0\n",
      "Episode 400, Reward: -3292.02, Cost: -1813.09, CO2: -5510.41, Violations: 0\n",
      "Episode 420, Reward: -2379.97, Cost: -1206.00, CO2: -4140.91, Violations: 0\n",
      "Episode 440, Reward: -3913.02, Cost: -2330.13, CO2: -6287.36, Violations: 1\n",
      "Episode 460, Reward: -4911.37, Cost: -3025.21, CO2: -7740.62, Violations: 0\n",
      "Episode 480, Reward: -2387.80, Cost: -1464.90, CO2: -3772.15, Violations: 0\n",
      "Episode 500, Reward: -2522.53, Cost: -1369.36, CO2: -4252.28, Violations: 0\n",
      "Episode 520, Reward: -1572.62, Cost: -952.16, CO2: -2503.32, Violations: 0\n",
      "Episode 540, Reward: -2528.89, Cost: -1516.27, CO2: -4047.81, Violations: 0\n",
      "Episode 560, Reward: -1523.82, Cost: -758.62, CO2: -2671.62, Violations: 0\n",
      "Episode 580, Reward: -1248.26, Cost: -756.77, CO2: -1985.50, Violations: 0\n",
      "Episode 600, Reward: -1782.10, Cost: -1089.59, CO2: -2820.85, Violations: 0\n",
      "Episode 620, Reward: -2817.35, Cost: -1843.83, CO2: -4277.61, Violations: 0\n",
      "Episode 640, Reward: -2727.77, Cost: -1987.11, CO2: -3838.78, Violations: 0\n",
      "Episode 660, Reward: -3261.89, Cost: -1967.63, CO2: -5203.27, Violations: 0\n",
      "Episode 680, Reward: -1922.44, Cost: -1192.54, CO2: -3017.27, Violations: 1\n",
      "Episode 700, Reward: -1432.36, Cost: -855.19, CO2: -2298.10, Violations: 0\n",
      "Episode 720, Reward: -1218.93, Cost: -700.74, CO2: -1996.22, Violations: 0\n",
      "Episode 740, Reward: -1907.93, Cost: -1199.81, CO2: -2970.12, Violations: 0\n",
      "Episode 760, Reward: -2047.60, Cost: -1336.35, CO2: -3114.47, Violations: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize Environment and Agent\n",
    "env = HybridEnergyEnv()  # Assuming this class is defined elsewhere\n",
    "agent = EnhancedQAgent(env, max_energy=200, alpha=0.1, epsilon_decay=0.995)\n",
    "\n",
    "# Training with tracking of cost and CO2 separately\n",
    "print(\"Training the Q-learning agent...\")\n",
    "rewards, cost_history, co2_history, violations_history = agent.train(episodes=2000, max_steps=15000)\n",
    "\n",
    "# Testing with separate metrics\n",
    "print(\"\\nTesting the trained Q-learning agent...\")\n",
    "agent_reward, agent_cost, agent_co2, agent_violations = test_agent(agent, episodes=100)\n",
    "\n",
    "# Test naive strategy with separate metrics\n",
    "print(\"\\nTesting naive strategy...\")\n",
    "naive_reward, naive_cost, naive_co2, naive_violations = naive_strategy(env, episodes=500, max_energy=200)\n",
    "\n",
    "# Calculate percentage improvements\n",
    "cost_improvement = ((naive_cost - agent_cost) / abs(naive_cost)) * 100\n",
    "co2_improvement = ((naive_co2 - agent_co2) / abs(naive_co2)) * 100\n",
    "violations_improvement = ((naive_violations - agent_violations) / (naive_violations + 1)) * 100  # Add 1 to avoid division by zero\n",
    "\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(f\"Cost improvement: {cost_improvement:.2f}%\")\n",
    "print(f\"CO2 emissions improvement: {co2_improvement:.2f}%\")\n",
    "print(f\"Energy violations improvement: {violations_improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b4bd5-4f96-4b50-bbe6-14b3bfe97c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training Progress\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Plot 1: Overall rewards\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(rewards)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.title(\"Q-learning Training Progress\")\n",
    "\n",
    "# Plot 2: Cost history\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(cost_history)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.title(\"Cost Progress During Training\")\n",
    "\n",
    "# Plot 3: CO2 history\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(co2_history)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"CO2 Emissions\")\n",
    "plt.title(\"CO2 Emissions Progress During Training\")\n",
    "\n",
    "# Plot 4: Energy violations\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(violations_history)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Energy Violations\")\n",
    "plt.title(\"Energy Violations During Training\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_progress.png\")\n",
    "plt.show()\n",
    "\n",
    "# Plot comparison between Q-learning and naive strategy\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Metrics to compare\n",
    "metrics = ['Reward', 'Cost', 'CO2', 'Violations']\n",
    "q_learning_values = [agent_reward, agent_cost, agent_co2, agent_violations]\n",
    "naive_values = [naive_reward, naive_cost, naive_co2, naive_violations]\n",
    "\n",
    "# Calculate percentage improvements for all metrics\n",
    "improvements = []\n",
    "for q_val, naive_val in zip(q_learning_values, naive_values):\n",
    "    if naive_val != 0:\n",
    "        imp = ((naive_val - q_val) / abs(naive_val)) * 100\n",
    "    else:\n",
    "        imp = 0 if q_val == 0 else 100\n",
    "    improvements.append(imp)\n",
    "\n",
    "# Plot bar chart\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, q_learning_values, width, label='Q-Learning')\n",
    "plt.bar(x + width/2, naive_values, width, label='Naive Strategy')\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Q-Learning vs Naive Strategy Comparison')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend()\n",
    "\n",
    "# Add improvement percentages as text\n",
    "for i, imp in enumerate(improvements):\n",
    "    plt.text(i, max(q_learning_values[i], naive_values[i]) + 0.1, \n",
    "             f\"{imp:.1f}%\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "# Plot comparison of cost and CO2 separately\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Set up data for side-by-side comparison\n",
    "labels = ['Cost', 'CO2 Emissions']\n",
    "q_learning_metrics = [agent_cost, agent_co2]\n",
    "naive_metrics = [naive_cost, naive_co2]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, q_learning_metrics, width, label='Q-Learning')\n",
    "plt.bar(x + width/2, naive_metrics, width, label='Naive Strategy')\n",
    "\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Cost and CO2 Emissions Comparison')\n",
    "plt.xticks(x, labels)\n",
    "plt.legend()\n",
    "\n",
    "# Add improvement percentages\n",
    "plt.text(0, min(agent_cost, naive_cost) - 5, f\"{cost_improvement:.1f}% improvement\", ha='center')\n",
    "plt.text(1, min(agent_co2, naive_co2) - 5, f\"{co2_improvement:.1f}% improvement\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cost_co2_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eece3fd-8dd4-40b1-b3c4-62950577502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def save_agent(agent, filepath='saved_agent.pkl'):\n",
    "    \"\"\"\n",
    "    Save the trained agent to a file using pickle\n",
    "    \n",
    "    Args:\n",
    "        agent: The EnhancedQAgent instance to save\n",
    "        filepath: Path where the agent will be saved\n",
    "    \"\"\"    \n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(agent, f)\n",
    "    \n",
    "    print(f\"Agent saved successfully to {filepath}\")\n",
    "    print(f\"Q-table size: {len(agent.q_table)} states\")\n",
    "\n",
    "\n",
    "def load_agent(filepath='saved_agent.pkl'):\n",
    "    \"\"\"\n",
    "    Load a previously saved agent\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the saved agent file\n",
    "        \n",
    "    Returns:\n",
    "        The loaded EnhancedQAgent instance\n",
    "    \"\"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        agent = pickle.load(f)\n",
    "    \n",
    "    print(f\"Agent loaded successfully from {filepath}\")\n",
    "    print(f\"Q-table size: {len(agent.q_table)} states\")\n",
    "    \n",
    "    return agent\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# After training\n",
    "save_agent(agent, 'enhanced_qagent_v1.pkl')\n",
    "\n",
    "# Later, to load the agent\n",
    "# loaded_agent = load_agent('models/enhanced_qagent_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3c1d6-3ec2-4d69-bc98-d8fc5debd982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_agent_performance(agent, env, rewards_history, episodes=5, max_steps=20, sample_size=100):\n",
    "\n",
    "    # Calculate average contribution of each energy source\n",
    "    avg_pv_energy = np.mean(test_data['pv_energy'])\n",
    "    avg_wt_energy = np.mean(test_data['wt_energy'])\n",
    "    avg_grid_energy = np.mean(test_data['grid'])\n",
    "    total_avg = avg_pv_energy + avg_wt_energy + avg_grid_energy\n",
    "\n",
    "    # Create energy mix pie chart\n",
    "    energy_sources = ['PV Panels', 'Wind Turbines', 'Grid']\n",
    "    energy_values = [avg_pv_energy, avg_wt_energy, avg_grid_energy]\n",
    "\n",
    "    plt.pie(energy_values, labels=energy_sources, autopct='%1.1f%%',\n",
    "            startangle=90, shadow=True, explode=(0.05, 0.05, 0.05),\n",
    "            colors=['gold', 'skyblue', 'lightgreen'])\n",
    "    plt.title(f'Average Energy Source Mix\\nTotal: {total_avg:.1f} units')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cc016f-f469-46f4-a546-41e3bbffe140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_actions(agent, states):\n",
    "    \"\"\"\n",
    "    Get the best actions for multiple states using the trained Q-table,\n",
    "    ensuring demand is always met while minimizing grid usage when possible.\n",
    "\n",
    "    Parameters:\n",
    "    - agent: The QAgent instance\n",
    "    - states: List of states to evaluate\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary mapping each state to its best action tuple (pv, wt, grid)\n",
    "    \"\"\"\n",
    "    best_actions = {}\n",
    "\n",
    "    for state in states:\n",
    "        state_key = agent.discretize_state(state)  # Convert to discrete form\n",
    "\n",
    "        # Extract demand from state (assuming demand is the 3rd element)\n",
    "        demand = state[2]\n",
    "\n",
    "        if state_key in agent.q_table and agent.q_table[state_key]:\n",
    "            # Find the index of the best action from Q-table\n",
    "            best_idx = max(agent.q_table[state_key], key=agent.q_table[state_key].get)\n",
    "            # Convert index back to action tuple\n",
    "            best_action = agent.idx_to_action(best_idx)\n",
    "        else:\n",
    "            # Fallback to a random action if state is not in Q-table\n",
    "            pv = random.choice(agent.action_space_pv)\n",
    "            wt = random.choice(agent.action_space_wt)\n",
    "            grid = random.choice(agent.action_space_grid)\n",
    "            best_action = (pv, wt, grid)\n",
    "\n",
    "        # Calculate energy from renewables with the selected action\n",
    "        pv_count, wt_count, _ = best_action\n",
    "        pv_power = state[0]  # Default if not in state\n",
    "        wind_power = state[1]        # Default if not in state\n",
    "\n",
    "\n",
    "        pv_energy = pv_count *  pv_power\n",
    "        wt_energy = wt_count * wind_power\n",
    "        renewable_energy = pv_energy + wt_energy\n",
    "\n",
    "        # Determine required grid power to meet demand\n",
    "        required_grid_power = max(0, demand - renewable_energy)\n",
    "\n",
    "        # Find closest grid power value in discretized space that meets or exceeds requirement\n",
    "        grid_options = [g for g in agent.action_space_grid if g >= required_grid_power]\n",
    "        if grid_options:\n",
    "            # Choose the smallest grid power that meets demand\n",
    "            new_grid_power = min(grid_options)\n",
    "        else:\n",
    "            # If no grid option is large enough, take the maximum available\n",
    "            new_grid_power = max(agent.action_space_grid)\n",
    "\n",
    "        # Create the adjusted action\n",
    "        adjusted_action = (pv_count, wt_count, new_grid_power)\n",
    "\n",
    "        # Check if this meets demand\n",
    "        total_energy = renewable_energy + new_grid_power\n",
    "        if total_energy < demand:\n",
    "            # This scenario should be rare given our grid power selection\n",
    "            # But if it happens, we need to adjust renewables upward\n",
    "\n",
    "            # Try different combinations of PV and WT\n",
    "            best_solution = None\n",
    "            min_excess = float('inf')\n",
    "\n",
    "            for p in sorted(agent.action_space_pv, reverse=True):\n",
    "                for w in sorted(agent.action_space_wt, reverse=True):\n",
    "                    p_energy = p * pv_power\n",
    "                    w_energy = w * wind_power\n",
    "                    r_energy = p_energy + w_energy\n",
    "\n",
    "                    # Calculate remaining demand\n",
    "                    remaining = max(0, demand - r_energy)\n",
    "\n",
    "                    # Find grid power that meets or exceeds remaining demand\n",
    "                    grid_options = [g for g in agent.action_space_grid if g >= remaining]\n",
    "                    if grid_options:\n",
    "                        g = min(grid_options)\n",
    "                        test_total = r_energy + g\n",
    "                        excess = test_total - demand\n",
    "\n",
    "                        # Keep track of solution with minimum excess\n",
    "                        if excess < min_excess:\n",
    "                            min_excess = excess\n",
    "                            best_solution = (p, w, g)\n",
    "\n",
    "            if best_solution:\n",
    "                adjusted_action = best_solution\n",
    "\n",
    "        best_actions[tuple(state)] = adjusted_action\n",
    "\n",
    "    return best_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9073fb3-21bc-4dbc-bfbb-0eb92a938e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 20 diverse example states\n",
    "import numpy as np\n",
    "\n",
    "# Generate random states with different solar irradiance, wind speed, and demand levels\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Create states with varying conditions\n",
    "test_states = []\n",
    "for _ in range(20):\n",
    "    solar = round(np.random.uniform(0, 0.4), 2)  # Solar irradiance between 0.1 and 1.0\n",
    "    wind = round(np.random.uniform(0, 20), 2)   # Wind speed between 0.1 and 1.0\n",
    "    demand = 200\n",
    "    test_states.append([solar, wind, demand])\n",
    "\n",
    "# Get best actions\n",
    "best_actions = get_best_actions(agent1, test_states)\n",
    "\n",
    "# Print results\n",
    "for state, action in best_actions.items():\n",
    "    solar = state[0]\n",
    "    wind = state[1]\n",
    "    demand = state[2]\n",
    "\n",
    "    pv_energy = action[0] *  solar\n",
    "    wt_energy = action[1] *  wind\n",
    "    renewable_energy = pv_energy + wt_energy\n",
    "    grid_energy = action[2]\n",
    "    total_energy = renewable_energy + grid_energy\n",
    "\n",
    "    print(f\"State: Solar={solar:.2f}, Wind={wind:.2f}, Demand={demand}\")\n",
    "    print(f\"  Action: PV panels={action[0]}, Wind turbines={action[1]}, Grid power={action[2]}\")\n",
    "    print(f\"  Renewable energy: {renewable_energy:.2f}\")\n",
    "    print(f\"  Grid energy: {grid_energy:.2f}\")\n",
    "    print(f\"  Total energy: {total_energy:.2f}\")\n",
    "    print(f\"  Demand met: {'Yes' if total_energy >= demand else 'No'}\")\n",
    "    print(f\"  Excess energy: {max(0, total_energy - demand):.2f}\")\n",
    "    print()\n",
    "\n",
    "# Summary stats\n",
    "demand_met_count = sum(1 for state, action in best_actions.items()\n",
    "                      if agent.estimate_total_energy(action, state) >= state[2])\n",
    "print(f\"Demand met in {demand_met_count} out of {len(test_states)} states ({demand_met_count/len(test_states)*100:.1f}%)\")\n",
    "\n",
    "# Calculate average excess energy\n",
    "avg_excess = sum(max(0, agent.estimate_total_energy(action, state) - state[2])\n",
    "                for state, action in best_actions.items()) / len(test_states)\n",
    "print(f\"Average excess energy: {avg_excess:.2f}\")\n",
    "\n",
    "# Calculate average renewable vs grid usage\n",
    "avg_renewable = sum((action[0] *  state[0] + action[1] *  state[1])\n",
    "                   for state, action in best_actions.items()) / len(test_states)\n",
    "avg_grid = sum(action[2] for state, action in best_actions.items()) / len(test_states)\n",
    "print(f\"Average renewable energy: {avg_renewable:.2f}\")\n",
    "print(f\"Average grid energy: {avg_grid:.2f}\")\n",
    "print(f\"Renewable percentage: {avg_renewable/(avg_renewable+avg_grid)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4323fc4a-20fa-4b4f-a47f-cd94d97ada60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def compare_agents_detailed(agent1, test_states, env, naive_strategy):\n",
    "    \"\"\"\n",
    "    Compare performance of a trained RL agent against a naive rule-based strategy\n",
    "    on the same set of test states, including cost and CO2 emissions analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    - agent1: The trained RL agent\n",
    "    - test_states: List of states to evaluate both agents on\n",
    "    - env: Environment object for the naive strategy\n",
    "    - naive_strategy: Function implementing the naive strategy\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with comparative results\n",
    "    \"\"\"\n",
    "    # Get best actions for the RL agent\n",
    "    rl_best_actions = get_best_actions(agent1, test_states)\n",
    "    \n",
    "    # Run naive strategy\n",
    "    naive_reward, naive_cost, naive_co2, naive_violations = naive_strategy(env, episodes=1, max_steps=len(test_states))\n",
    "    \n",
    "    # Apply naive strategy to the same test states for direct comparison\n",
    "    naive_best_actions = {}\n",
    "    \n",
    "    # For each test state, compute what the naive strategy would do\n",
    "    for state in test_states:\n",
    "        pv_factor = state[0]  # Solar power factor\n",
    "        wind_factor = state[1]  # Wind power factor\n",
    "        demand = state[2]  # Energy demand\n",
    "        grid_price = 0.10  # Default grid price if not in state\n",
    "        \n",
    "        # Extend state with grid price if needed\n",
    "        if len(state) < 4:\n",
    "            state_with_price = list(state) + [grid_price]\n",
    "        else:\n",
    "            state_with_price = state\n",
    "            grid_price = state[3]\n",
    "        \n",
    "        # Apply naive strategy rules\n",
    "        if pv_factor > 0.6:\n",
    "            pv_panels = 200\n",
    "        elif pv_factor > 0.3:\n",
    "            pv_panels = 150\n",
    "        else:\n",
    "            pv_panels = 50\n",
    "        \n",
    "        if wind_factor > 0.7:\n",
    "            wind_turbines = 35\n",
    "        elif wind_factor > 0.4:\n",
    "            wind_turbines = 20\n",
    "        else:\n",
    "            wind_turbines = 5\n",
    "        \n",
    "        # Calculate expected renewable energy\n",
    "        renewable_energy = (pv_panels * pv_factor) + (wind_turbines * wind_factor)\n",
    "        \n",
    "        # Determine grid power with 10% buffer\n",
    "        grid_power = max(0, min(1000, (demand - renewable_energy) * 1.1))\n",
    "        grid_power = round(grid_power / 50) * 50\n",
    "        \n",
    "        # Check for energy constraint violation\n",
    "        total_energy = pv_panels * pv_factor + wind_turbines * wind_factor + grid_power\n",
    "        if total_energy > demand:\n",
    "            # Adjust grid power down\n",
    "            excess = total_energy - demand\n",
    "            adjusted_grid = max(0, grid_power - excess)\n",
    "            # Round to nearest increment\n",
    "            adjusted_grid = round(adjusted_grid / 50) * 50\n",
    "            naive_action = (pv_panels, wind_turbines, adjusted_grid)\n",
    "        else:\n",
    "            naive_action = (pv_panels, wind_turbines, grid_power)\n",
    "            \n",
    "        naive_best_actions[tuple(state_with_price)] = naive_action\n",
    "    \n",
    "    # Calculate detailed metrics for both agents\n",
    "    rl_metrics = []\n",
    "    naive_metrics = []\n",
    "    \n",
    "    for i, state in enumerate(test_states):\n",
    "        # Ensure state has grid price\n",
    "        if len(state) < 4:\n",
    "            state_with_price = list(state) + [0.10]  # Default grid price\n",
    "        else:\n",
    "            state_with_price = state\n",
    "        \n",
    "        state_tuple = tuple(state_with_price)\n",
    "        \n",
    "        # Get actions for this state\n",
    "        if state_tuple in rl_best_actions:\n",
    "            rl_action = rl_best_actions[state_tuple]\n",
    "        else:\n",
    "            # If the state with price isn't in rl_best_actions, try without price\n",
    "            original_state_tuple = tuple(state)\n",
    "            if original_state_tuple in rl_best_actions:\n",
    "                rl_action = rl_best_actions[original_state_tuple]\n",
    "            else:\n",
    "                # Fallback to default action\n",
    "                rl_action = (100, 10, 100)\n",
    "        \n",
    "        naive_action = naive_best_actions[state_tuple]\n",
    "        \n",
    "        # Calculate cost and CO2 for RL agent\n",
    "        rl_cost = -env.calculate_cost(rl_action, state_with_price)  # Negate because function returns negative cost\n",
    "        rl_co2 = -env.calculate_co2(rl_action, state_with_price)    # Negate because function returns negative CO2\n",
    "        \n",
    "        # Calculate cost and CO2 for naive agent\n",
    "        naive_cost = -env.calculate_cost(naive_action, state_with_price)\n",
    "        naive_co2 = -env.calculate_co2(naive_action, state_with_price)\n",
    "        \n",
    "        # Calculate energy production for RL agent\n",
    "        solar = state[0]\n",
    "        wind = state[1]\n",
    "        demand = state[2]\n",
    "        \n",
    "        rl_pv_energy = rl_action[0] * solar\n",
    "        rl_wt_energy = rl_action[1] * wind\n",
    "        rl_renewable_energy = rl_pv_energy + rl_wt_energy\n",
    "        rl_grid_energy = rl_action[2]\n",
    "        rl_total_energy = rl_renewable_energy + rl_grid_energy\n",
    "        rl_excess = max(0, rl_total_energy - demand)\n",
    "        rl_demand_met = rl_total_energy >= demand\n",
    "        \n",
    "        # Calculate energy production for naive strategy\n",
    "        naive_pv_energy = naive_action[0] * solar\n",
    "        naive_wt_energy = naive_action[1] * wind\n",
    "        naive_renewable_energy = naive_pv_energy + naive_wt_energy\n",
    "        naive_grid_energy = naive_action[2]\n",
    "        naive_total_energy = naive_renewable_energy + naive_grid_energy\n",
    "        naive_excess = max(0, naive_total_energy - demand)\n",
    "        naive_demand_met = naive_total_energy >= demand\n",
    "        \n",
    "        # Store metrics for each state\n",
    "        rl_metrics.append({\n",
    "            'state_index': i,\n",
    "            'solar': solar,\n",
    "            'wind': wind,\n",
    "            'demand': demand,\n",
    "            'pv_panels': rl_action[0],\n",
    "            'wind_turbines': rl_action[1],\n",
    "            'grid_power': rl_action[2],\n",
    "            'pv_energy': rl_pv_energy,\n",
    "            'wt_energy': rl_wt_energy,\n",
    "            'renewable_energy': rl_renewable_energy,\n",
    "            'grid_energy': rl_grid_energy,\n",
    "            'total_energy': rl_total_energy,\n",
    "            'excess_energy': rl_excess,\n",
    "            'demand_met': rl_demand_met,\n",
    "            'cost': rl_cost,\n",
    "            'co2': rl_co2,\n",
    "            'renewable_percentage': rl_renewable_energy / rl_total_energy * 100 if rl_total_energy > 0 else 0\n",
    "        })\n",
    "        \n",
    "        naive_metrics.append({\n",
    "            'state_index': i,\n",
    "            'solar': solar,\n",
    "            'wind': wind,\n",
    "            'demand': demand,\n",
    "            'pv_panels': naive_action[0],\n",
    "            'wind_turbines': naive_action[1],\n",
    "            'grid_power': naive_action[2],\n",
    "            'pv_energy': naive_pv_energy,\n",
    "            'wt_energy': naive_wt_energy,\n",
    "            'renewable_energy': naive_renewable_energy,\n",
    "            'grid_energy': naive_grid_energy,\n",
    "            'total_energy': naive_total_energy,\n",
    "            'excess_energy': naive_excess,\n",
    "            'demand_met': naive_demand_met,\n",
    "            'cost': naive_cost,\n",
    "            'co2': naive_co2,\n",
    "            'renewable_percentage': naive_renewable_energy / naive_total_energy * 100 if naive_total_energy > 0 else 0\n",
    "        })\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\n=== COMPARATIVE ANALYSIS: RL AGENT VS NAIVE STRATEGY ===\\n\")\n",
    "    \n",
    "    # Print detailed results for each state\n",
    "    print(\"DETAILED STATE ANALYSIS:\")\n",
    "    for i, (rl_metric, naive_metric) in enumerate(zip(rl_metrics, naive_metrics)):\n",
    "        print(f\"\\nState {i+1}: Solar={rl_metric['solar']:.2f}, Wind={rl_metric['wind']:.2f}, Demand={rl_metric['demand']}\")\n",
    "        \n",
    "        print(\"  RL Agent:\")\n",
    "        print(f\"    Action: PV panels={rl_metric['pv_panels']}, Wind turbines={rl_metric['wind_turbines']}, Grid power={rl_metric['grid_power']}\")\n",
    "        print(f\"    Renewable energy: {rl_metric['renewable_energy']:.2f}\")\n",
    "        print(f\"    Grid energy: {rl_metric['grid_energy']:.2f}\")\n",
    "        print(f\"    Total energy: {rl_metric['total_energy']:.2f}\")\n",
    "        print(f\"    Demand met: {'Yes' if rl_metric['demand_met'] else 'No'}\")\n",
    "        print(f\"    Excess energy: {rl_metric['excess_energy']:.2f}\")\n",
    "        print(f\"    Cost: ${rl_metric['cost']:.2f}\")\n",
    "        print(f\"    CO2 emissions: {rl_metric['co2']:.2f} kg\")\n",
    "        \n",
    "        print(\"  Naive Strategy:\")\n",
    "        print(f\"    Action: PV panels={naive_metric['pv_panels']}, Wind turbines={naive_metric['wind_turbines']}, Grid power={naive_metric['grid_power']}\")\n",
    "        print(f\"    Renewable energy: {naive_metric['renewable_energy']:.2f}\")\n",
    "        print(f\"    Grid energy: {naive_metric['grid_energy']:.2f}\")\n",
    "        print(f\"    Total energy: {naive_metric['total_energy']:.2f}\")\n",
    "        print(f\"    Demand met: {'Yes' if naive_metric['demand_met'] else 'No'}\")\n",
    "        print(f\"    Excess energy: {naive_metric['excess_energy']:.2f}\")\n",
    "        print(f\"    Cost: ${naive_metric['cost']:.2f}\")\n",
    "        print(f\"    CO2 emissions: {naive_metric['co2']:.2f} kg\")\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    rl_summary = {\n",
    "        'demand_met_count': sum(1 for m in rl_metrics if m['demand_met']),\n",
    "        'avg_excess': np.mean([m['excess_energy'] for m in rl_metrics]),\n",
    "        'avg_renewable': np.mean([m['renewable_energy'] for m in rl_metrics]),\n",
    "        'avg_grid': np.mean([m['grid_energy'] for m in rl_metrics]),\n",
    "        'avg_cost': np.mean([m['cost'] for m in rl_metrics]),\n",
    "        'avg_co2': np.mean([m['co2'] for m in rl_metrics]),\n",
    "        'total_cost': sum([m['cost'] for m in rl_metrics]),\n",
    "        'total_co2': sum([m['co2'] for m in rl_metrics]),\n",
    "        'avg_renewable_percentage': np.mean([m['renewable_percentage'] for m in rl_metrics])\n",
    "    }\n",
    "    \n",
    "    naive_summary = {\n",
    "        'demand_met_count': sum(1 for m in naive_metrics if m['demand_met']),\n",
    "        'avg_excess': np.mean([m['excess_energy'] for m in naive_metrics]),\n",
    "        'avg_renewable': np.mean([m['renewable_energy'] for m in naive_metrics]),\n",
    "        'avg_grid': np.mean([m['grid_energy'] for m in naive_metrics]),\n",
    "        'avg_cost': np.mean([m['cost'] for m in naive_metrics]),\n",
    "        'avg_co2': np.mean([m['co2'] for m in naive_metrics]),\n",
    "        'total_cost': sum([m['cost'] for m in naive_metrics]),\n",
    "        'total_co2': sum([m['co2'] for m in naive_metrics]),\n",
    "        'avg_renewable_percentage': np.mean([m['renewable_percentage'] for m in naive_metrics])\n",
    "    }\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n=== SUMMARY STATISTICS ===\\n\")\n",
    "    \n",
    "    print(\"RL Agent:\")\n",
    "    print(f\"  Demand met in {rl_summary['demand_met_count']} out of {len(test_states)} states ({rl_summary['demand_met_count']/len(test_states)*100:.1f}%)\")\n",
    "    print(f\"  Average excess energy: {rl_summary['avg_excess']:.2f}\")\n",
    "    print(f\"  Average renewable energy: {rl_summary['avg_renewable']:.2f}\")\n",
    "    print(f\"  Average grid energy: {rl_summary['avg_grid']:.2f}\")\n",
    "    print(f\"  Renewable percentage: {rl_summary['avg_renewable_percentage']:.1f}%\")\n",
    "    print(f\"  Average cost: ${rl_summary['avg_cost']:.2f}\")\n",
    "    print(f\"  Total cost: ${rl_summary['total_cost']:.2f}\")\n",
    "    print(f\"  Average CO2 emissions: {rl_summary['avg_co2']:.2f} kg\")\n",
    "    print(f\"  Total CO2 emissions: {rl_summary['total_co2']:.2f} kg\")\n",
    "    \n",
    "    print(\"\\nNaive Strategy:\")\n",
    "    print(f\"  Demand met in {naive_summary['demand_met_count']} out of {len(test_states)} states ({naive_summary['demand_met_count']/len(test_states)*100:.1f}%)\")\n",
    "    print(f\"  Average excess energy: {naive_summary['avg_excess']:.2f}\")\n",
    "    print(f\"  Average renewable energy: {naive_summary['avg_renewable']:.2f}\")\n",
    "    print(f\"  Average grid energy: {naive_summary['avg_grid']:.2f}\")\n",
    "    print(f\"  Renewable percentage: {naive_summary['avg_renewable_percentage']:.1f}%\")\n",
    "    print(f\"  Average cost: ${naive_summary['avg_cost']:.2f}\")\n",
    "    print(f\"  Total cost: ${naive_summary['total_cost']:.2f}\")\n",
    "    print(f\"  Average CO2 emissions: {naive_summary['avg_co2']:.2f} kg\")\n",
    "    print(f\"  Total CO2 emissions: {naive_summary['total_co2']:.2f} kg\")\n",
    "    \n",
    "    # Calculate improvement metrics\n",
    "    improvement = {\n",
    "        'demand_met': (rl_summary['demand_met_count'] - naive_summary['demand_met_count']) / len(test_states) * 100,\n",
    "        'excess_energy': ((naive_summary['avg_excess'] - rl_summary['avg_excess']) / naive_summary['avg_excess'] * 100) if naive_summary['avg_excess'] > 0 else 0,\n",
    "        'renewable_percentage': rl_summary['avg_renewable_percentage'] - naive_summary['avg_renewable_percentage'],\n",
    "        'grid_reduction': ((naive_summary['avg_grid'] - rl_summary['avg_grid']) / naive_summary['avg_grid'] * 100) if naive_summary['avg_grid'] > 0 else 0,\n",
    "        'cost_reduction': ((naive_summary['avg_cost'] - rl_summary['avg_cost']) / naive_summary['avg_cost'] * 100) if naive_summary['avg_cost'] > 0 else 0,\n",
    "        'co2_reduction': ((naive_summary['avg_co2'] - rl_summary['avg_co2']) / naive_summary['avg_co2'] * 100) if naive_summary['avg_co2'] > 0 else 0\n",
    "    }\n",
    "    \n",
    "    # Print improvement analysis\n",
    "    print(\"\\n=== IMPROVEMENT ANALYSIS ===\\n\")\n",
    "    print(f\"Demand satisfaction: {'+' if improvement['demand_met'] >= 0 else ''}{improvement['demand_met']:.1f}% difference\")\n",
    "    print(f\"Excess energy reduction: {'+' if improvement['excess_energy'] >= 0 else ''}{improvement['excess_energy']:.1f}%\")\n",
    "    print(f\"Renewable utilization: {'+' if improvement['renewable_percentage'] >= 0 else ''}{improvement['renewable_percentage']:.1f}% difference\")\n",
    "    print(f\"Grid energy reduction: {'+' if improvement['grid_reduction'] >= 0 else ''}{improvement['grid_reduction']:.1f}%\")\n",
    "    print(f\"Cost reduction: {'+' if improvement['cost_reduction'] >= 0 else ''}{improvement['cost_reduction']:.1f}%\")\n",
    "    print(f\"CO2 emissions reduction: {'+' if improvement['co2_reduction'] >= 0 else ''}{improvement['co2_reduction']:.1f}%\")\n",
    "\n",
    "    # Create visualizations\n",
    "    create_visualizations(rl_metrics, naive_metrics, rl_summary, naive_summary)\n",
    "    \n",
    "    return {\n",
    "        'rl_metrics': rl_metrics,\n",
    "        'naive_metrics': naive_metrics,\n",
    "        'rl_summary': rl_summary,\n",
    "        'naive_summary': naive_summary,\n",
    "        'improvement': improvement\n",
    "    }\n",
    "\n",
    "def create_visualizations(rl_metrics, naive_metrics, rl_summary, naive_summary):\n",
    "    \"\"\"\n",
    "    Create visualizations comparing the RL agent and naive strategy.\n",
    "    \n",
    "    Parameters:\n",
    "    - rl_metrics: List of dictionaries with RL agent metrics\n",
    "    - naive_metrics: List of dictionaries with naive strategy metrics\n",
    "    - rl_summary: Dictionary with RL agent summary statistics\n",
    "    - naive_summary: Dictionary with naive strategy summary statistics\n",
    "    \"\"\"\n",
    "    # Set up a clean aesthetic for plots\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.rcParams.update({\n",
    "        'figure.figsize': (12, 8),\n",
    "        'font.size': 12,\n",
    "        'axes.titlesize': 16,\n",
    "        'axes.labelsize': 14\n",
    "    })\n",
    "    \n",
    "    # Visualization 1: Energy Composition Bar Chart\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Prepare data for energy composition\n",
    "    states = [i+1 for i in range(len(rl_metrics))]\n",
    "    \n",
    "    # Plot 1: Energy Composition for RL Agent and Naive Strategy\n",
    "    plt.subplot(2, 2, 1)\n",
    "    \n",
    "    # Extract data for plotting\n",
    "    rl_renewable = [m['renewable_energy'] for m in rl_metrics]\n",
    "    rl_grid = [m['grid_energy'] for m in rl_metrics]\n",
    "    naive_renewable = [m['renewable_energy'] for m in naive_metrics]\n",
    "    naive_grid = [m['grid_energy'] for m in naive_metrics]\n",
    "    \n",
    "    # Create the grouped bar chart\n",
    "    x = np.arange(len(states))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, rl_renewable, width, label='RL Renewable', color='#2ca02c')\n",
    "    plt.bar(x - width/2, rl_grid, width, bottom=rl_renewable, label='RL Grid', color='#d62728')\n",
    "    plt.bar(x + width/2, naive_renewable, width, label='Naive Renewable', color='#1f77b4')\n",
    "    plt.bar(x + width/2, naive_grid, width, bottom=naive_renewable, label='Naive Grid', color='#ff7f0e')\n",
    "    \n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('Energy (kW)')\n",
    "    plt.title('Energy Composition by State')\n",
    "    plt.xticks(x, states)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot 2: Cost Comparison\n",
    "    plt.subplot(2, 2, 2)\n",
    "    \n",
    "    # Extract cost data\n",
    "    rl_costs = [m['cost'] for m in rl_metrics]\n",
    "    naive_costs = [m['cost'] for m in naive_metrics]\n",
    "    \n",
    "    plt.bar(x - width/2, rl_costs, width, label='RL Agent', color='#2ca02c')\n",
    "    plt.bar(x + width/2, naive_costs, width, label='Naive Strategy', color='#1f77b4')\n",
    "    \n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('Cost ($)')\n",
    "    plt.title('Cost Comparison by State')\n",
    "    plt.xticks(x, states)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot 3: CO2 Emissions Comparison\n",
    "    plt.subplot(2, 2, 3)\n",
    "    \n",
    "    # Extract CO2 data\n",
    "    rl_co2 = [m['co2'] for m in rl_metrics]\n",
    "    naive_co2 = [m['co2'] for m in naive_metrics]\n",
    "    \n",
    "    plt.bar(x - width/2, rl_co2, width, label='RL Agent', color='#2ca02c')\n",
    "    plt.bar(x + width/2, naive_co2, width, label='Naive Strategy', color='#1f77b4')\n",
    "    \n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('CO2 Emissions (kg)')\n",
    "    plt.title('CO2 Emissions Comparison by State')\n",
    "    plt.xticks(x, states)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot 4: Renewable Percentage Comparison\n",
    "    plt.subplot(2, 2, 4)\n",
    "    \n",
    "    # Extract renewable percentage data\n",
    "    rl_renewable_pct = [m['renewable_percentage'] for m in rl_metrics]\n",
    "    naive_renewable_pct = [m['renewable_percentage'] for m in naive_metrics]\n",
    "    \n",
    "    plt.bar(x - width/2, rl_renewable_pct, width, label='RL Agent', color='#2ca02c')\n",
    "    plt.bar(x + width/2, naive_renewable_pct, width, label='Naive Strategy', color='#1f77b4')\n",
    "    \n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('Renewable Percentage (%)')\n",
    "    plt.title('Renewable Energy Percentage by State')\n",
    "    plt.xticks(x, states)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('energy_state_comparison.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Visualization 2: Summary Statistics\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Summary metrics to plot\n",
    "    metrics = ['avg_renewable', 'avg_grid', 'avg_cost', 'avg_co2']\n",
    "    metric_labels = ['Avg. Renewable Energy (kW)', 'Avg. Grid Energy (kW)', 'Avg. Cost ($)', 'Avg. CO2 Emissions (kg)']\n",
    "    \n",
    "    for i, (metric, label) in enumerate(zip(metrics, metric_labels)):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        \n",
    "        # Extract data\n",
    "        rl_value = rl_summary[metric]\n",
    "        naive_value = naive_summary[metric]\n",
    "        \n",
    "        # Create bar chart\n",
    "        plt.bar(['RL Agent', 'Naive Strategy'], [rl_value, naive_value], color=['#2ca02c', '#1f77b4'])\n",
    "        \n",
    "        plt.ylabel(label)\n",
    "        plt.title(f'{label} Comparison')\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for j, v in enumerate([rl_value, naive_value]):\n",
    "            plt.text(j, v, f'{v:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('summary_comparison.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Visualization 3: Improvement Analysis\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Prepare improvement data\n",
    "    improvement_metrics = [\n",
    "        'demand_met', 'excess_energy', 'renewable_percentage', \n",
    "        'grid_reduction', 'cost_reduction', 'co2_reduction'\n",
    "    ]\n",
    "    metric_labels = [\n",
    "        'Demand Met (%)', 'Excess Energy Reduction (%)', 'Renewable % Increase', \n",
    "        'Grid Energy Reduction (%)', 'Cost Reduction (%)', 'CO2 Reduction (%)'\n",
    "    ]\n",
    "    \n",
    "    # Extract improvement values\n",
    "    improvements = [\n",
    "        (rl_summary['demand_met_count'] - naive_summary['demand_met_count']) / len(rl_metrics) * 100,\n",
    "        ((naive_summary['avg_excess'] - rl_summary['avg_excess']) / naive_summary['avg_excess'] * 100) if naive_summary['avg_excess'] > 0 else 0,\n",
    "        rl_summary['avg_renewable_percentage'] - naive_summary['avg_renewable_percentage'],\n",
    "        ((naive_summary['avg_grid'] - rl_summary['avg_grid']) / naive_summary['avg_grid'] * 100) if naive_summary['avg_grid'] > 0 else 0,\n",
    "        ((naive_summary['avg_cost'] - rl_summary['avg_cost']) / naive_summary['avg_cost'] * 100) if naive_summary['avg_cost'] > 0 else 0,\n",
    "        ((naive_summary['avg_co2'] - rl_summary['avg_co2']) / naive_summary['avg_co2'] * 100) if naive_summary['avg_co2'] > 0 else 0\n",
    "    ]\n",
    "    \n",
    "    # Create bar chart of improvements\n",
    "    colors = ['#2ca02c' if i >= 0 else '#d62728' for i in improvements]\n",
    "    plt.bar(metric_labels, improvements, color=colors)\n",
    "    \n",
    "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "    plt.ylabel('Improvement (%)')\n",
    "    plt.title('RL Agent Improvement over Naive Strategy')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(improvements):\n",
    "        plt.text(i, v, f'{v:.1f}%', ha='center', va='bottom' if v >= 0 else 'top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('improvement_analysis.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Visualization 4: Scatter plot of renewable energy vs cost\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Extract data for scatter plot\n",
    "    rl_renewable_energy = [m['renewable_energy'] for m in rl_metrics]\n",
    "    rl_cost = [m['cost'] for m in rl_metrics]\n",
    "    naive_renewable_energy = [m['renewable_energy'] for m in naive_metrics]\n",
    "    naive_cost = [m['cost'] for m in naive_metrics]\n",
    "    \n",
    "    plt.scatter(rl_renewable_energy, rl_cost, label='RL Agent', color='#2ca02c', alpha=0.7, s=100)\n",
    "    plt.scatter(naive_renewable_energy, naive_cost, label='Naive Strategy', color='#1f77b4', alpha=0.7, s=100)\n",
    "    \n",
    "    # Add trend lines\n",
    "    z_rl = np. polyfit(rl_renewable_energy, rl_cost, 1)\n",
    "    p_rl = np.poly1d(z_rl)\n",
    "    plt.plot(np.sort(rl_renewable_energy), p_rl(np.sort(rl_renewable_energy)), color='#2ca02c', linestyle='--')\n",
    "    \n",
    "    z_naive = np.polyfit(naive_renewable_energy, naive_cost, 1)\n",
    "    p_naive = np.poly1d(z_naive)\n",
    "    plt.plot(np.sort(naive_renewable_energy), p_naive(np.sort(naive_renewable_energy)), color='#1f77b4', linestyle='--')\n",
    "    \n",
    "    plt.xlabel('Renewable Energy (kW)')\n",
    "    plt.ylabel('Cost ($)')\n",
    "    plt.title('Renewable Energy vs Cost')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('renewable_vs_cost.png')\n",
    "    plt.close()\n",
    "\n",
    "# Example usage:\n",
    "results = compare_agents_detailed(agent, test_states, env, naive_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748ccecf-4144-4cf4-97a8-e75d4eea9d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def compare_rl_vs_grid_only(agent, test_states, env):\n",
    "    \"\"\"\n",
    "    Compare performance of a trained RL agent against a grid-only strategy\n",
    "    on the same set of test states, including cost and CO2 emissions analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    - agent: The trained RL agent\n",
    "    - test_states: List of states to evaluate both agents on\n",
    "    - env: Environment object for the strategies\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with comparative results\n",
    "    \"\"\"\n",
    "    # Get best actions for the RL agent\n",
    "    rl_best_actions = get_best_actions(agent, test_states)\n",
    "    \n",
    "    # Define the grid-only strategy\n",
    "    grid_only_best_actions = {}\n",
    "    \n",
    "    # For each test state, compute what the grid-only strategy would do\n",
    "    for state in test_states:\n",
    "        pv_factor = state[0]  # Solar power factor\n",
    "        wind_factor = state[1]  # Wind power factor\n",
    "        demand = state[2]  # Energy demand\n",
    "        grid_price = 0.10  # Default grid price if not in state\n",
    "        \n",
    "        # Extend state with grid price if needed\n",
    "        if len(state) < 4:\n",
    "            state_with_price = list(state) + [grid_price]\n",
    "        else:\n",
    "            state_with_price = state\n",
    "            grid_price = state[3]\n",
    "        \n",
    "        # Grid-only strategy: No renewable energy, all grid power\n",
    "        pv_panels = 0\n",
    "        wind_turbines = 0\n",
    "        \n",
    "        # Set grid power to meet demand exactly\n",
    "        grid_power = demand\n",
    "        \n",
    "        grid_only_action = (pv_panels, wind_turbines, grid_power)\n",
    "        grid_only_best_actions[tuple(state_with_price)] = grid_only_action\n",
    "    \n",
    "    # Calculate detailed metrics for both agents\n",
    "    rl_metrics = []\n",
    "    grid_only_metrics = []\n",
    "    \n",
    "    for i, state in enumerate(test_states):\n",
    "        # Ensure state has grid price\n",
    "        if len(state) < 4:\n",
    "            state_with_price = list(state) + [0.10]  # Default grid price\n",
    "        else:\n",
    "            state_with_price = state\n",
    "        \n",
    "        state_tuple = tuple(state_with_price)\n",
    "        \n",
    "        # Get actions for this state\n",
    "        if state_tuple in rl_best_actions:\n",
    "            rl_action = rl_best_actions[state_tuple]\n",
    "        else:\n",
    "            # If the state with price isn't in rl_best_actions, try without price\n",
    "            original_state_tuple = tuple(state)\n",
    "            if original_state_tuple in rl_best_actions:\n",
    "                rl_action = rl_best_actions[original_state_tuple]\n",
    "            else:\n",
    "                # Fallback to default action\n",
    "                rl_action = (100, 10, 100)\n",
    "        \n",
    "        grid_only_action = grid_only_best_actions[state_tuple]\n",
    "        \n",
    "        # Calculate cost and CO2 for RL agent\n",
    "        rl_cost = -env.calculate_cost(rl_action, state_with_price)  # Negate because function returns negative cost\n",
    "        rl_co2 = -env.calculate_co2(rl_action, state_with_price)    # Negate because function returns negative CO2\n",
    "        \n",
    "        # Calculate cost and CO2 for grid-only agent\n",
    "        grid_only_cost = -env.calculate_cost(grid_only_action, state_with_price)\n",
    "        grid_only_co2 = -env.calculate_co2(grid_only_action, state_with_price)\n",
    "        \n",
    "        # Calculate energy production for RL agent\n",
    "        solar = state[0]\n",
    "        wind = state[1]\n",
    "        demand = state[2]\n",
    "        \n",
    "        rl_pv_energy = rl_action[0] * solar\n",
    "        rl_wt_energy = rl_action[1] * wind\n",
    "        rl_renewable_energy = rl_pv_energy + rl_wt_energy\n",
    "        rl_grid_energy = rl_action[2]\n",
    "        rl_total_energy = rl_renewable_energy + rl_grid_energy\n",
    "        rl_excess = max(0, rl_total_energy - demand)\n",
    "        rl_demand_met = rl_total_energy >= demand\n",
    "        \n",
    "        # Calculate energy production for grid-only strategy\n",
    "        grid_only_pv_energy = grid_only_action[0] * solar  # Always 0\n",
    "        grid_only_wt_energy = grid_only_action[1] * wind   # Always 0\n",
    "        grid_only_renewable_energy = grid_only_pv_energy + grid_only_wt_energy  # Always 0\n",
    "        grid_only_grid_energy = grid_only_action[2]  # Equal to demand\n",
    "        grid_only_total_energy = grid_only_renewable_energy + grid_only_grid_energy\n",
    "        grid_only_excess = max(0, grid_only_total_energy - demand)  # Should be 0\n",
    "        grid_only_demand_met = grid_only_total_energy >= demand  # Should be True\n",
    "        \n",
    "        # Store metrics for each state\n",
    "        rl_metrics.append({\n",
    "            'state_index': i,\n",
    "            'solar': solar,\n",
    "            'wind': wind,\n",
    "            'demand': demand,\n",
    "            'pv_panels': rl_action[0],\n",
    "            'wind_turbines': rl_action[1],\n",
    "            'grid_power': rl_action[2],\n",
    "            'pv_energy': rl_pv_energy,\n",
    "            'wt_energy': rl_wt_energy,\n",
    "            'renewable_energy': rl_renewable_energy,\n",
    "            'grid_energy': rl_grid_energy,\n",
    "            'total_energy': rl_total_energy,\n",
    "            'excess_energy': rl_excess,\n",
    "            'demand_met': rl_demand_met,\n",
    "            'cost': rl_cost,\n",
    "            'co2': rl_co2,\n",
    "            'renewable_percentage': rl_renewable_energy / rl_total_energy * 100 if rl_total_energy > 0 else 0\n",
    "        })\n",
    "        \n",
    "        grid_only_metrics.append({\n",
    "            'state_index': i,\n",
    "            'solar': solar,\n",
    "            'wind': wind,\n",
    "            'demand': demand,\n",
    "            'pv_panels': grid_only_action[0],\n",
    "            'wind_turbines': grid_only_action[1],\n",
    "            'grid_power': grid_only_action[2],\n",
    "            'pv_energy': grid_only_pv_energy,\n",
    "            'wt_energy': grid_only_wt_energy,\n",
    "            'renewable_energy': grid_only_renewable_energy,\n",
    "            'grid_energy': grid_only_grid_energy,\n",
    "            'total_energy': grid_only_total_energy,\n",
    "            'excess_energy': grid_only_excess,\n",
    "            'demand_met': grid_only_demand_met,\n",
    "            'cost': grid_only_cost,\n",
    "            'co2': grid_only_co2,\n",
    "            'renewable_percentage': 0  # Always 0% renewable for grid-only\n",
    "        })\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\n=== COMPARATIVE ANALYSIS: RL AGENT VS GRID-ONLY STRATEGY ===\\n\")\n",
    "    \n",
    "    # Print detailed results for each state\n",
    "    print(\"DETAILED STATE ANALYSIS:\")\n",
    "    for i, (rl_metric, grid_only_metric) in enumerate(zip(rl_metrics, grid_only_metrics)):\n",
    "        print(f\"\\nState {i+1}: Solar={rl_metric['solar']:.2f}, Wind={rl_metric['wind']:.2f}, Demand={rl_metric['demand']}\")\n",
    "        \n",
    "        print(\"  RL Agent:\")\n",
    "        print(f\"    Action: PV panels={rl_metric['pv_panels']}, Wind turbines={rl_metric['wind_turbines']}, Grid power={rl_metric['grid_power']}\")\n",
    "        print(f\"    Renewable energy: {rl_metric['renewable_energy']:.2f}\")\n",
    "        print(f\"    Grid energy: {rl_metric['grid_energy']:.2f}\")\n",
    "        print(f\"    Total energy: {rl_metric['total_energy']:.2f}\")\n",
    "        print(f\"    Demand met: {'Yes' if rl_metric['demand_met'] else 'No'}\")\n",
    "        print(f\"    Excess energy: {rl_metric['excess_energy']:.2f}\")\n",
    "        print(f\"    Cost: ${rl_metric['cost']:.2f}\")\n",
    "        print(f\"    CO2 emissions: {rl_metric['co2']:.2f} kg\")\n",
    "        \n",
    "        print(\"  Grid-Only Strategy:\")\n",
    "        print(f\"    Action: PV panels={grid_only_metric['pv_panels']}, Wind turbines={grid_only_metric['wind_turbines']}, Grid power={grid_only_metric['grid_power']}\")\n",
    "        print(f\"    Renewable energy: {grid_only_metric['renewable_energy']:.2f}\")\n",
    "        print(f\"    Grid energy: {grid_only_metric['grid_energy']:.2f}\")\n",
    "        print(f\"    Total energy: {grid_only_metric['total_energy']:.2f}\")\n",
    "        print(f\"    Demand met: {'Yes' if grid_only_metric['demand_met'] else 'No'}\")\n",
    "        print(f\"    Excess energy: {grid_only_metric['excess_energy']:.2f}\")\n",
    "        print(f\"    Cost: ${grid_only_metric['cost']:.2f}\")\n",
    "        print(f\"    CO2 emissions: {grid_only_metric['co2']:.2f} kg\")\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    rl_summary = {\n",
    "        'demand_met_count': sum(1 for m in rl_metrics if m['demand_met']),\n",
    "        'avg_excess': np.mean([m['excess_energy'] for m in rl_metrics]),\n",
    "        'avg_renewable': np.mean([m['renewable_energy'] for m in rl_metrics]),\n",
    "        'avg_grid': np.mean([m['grid_energy'] for m in rl_metrics]),\n",
    "        'avg_cost': np.mean([m['cost'] for m in rl_metrics]),\n",
    "        'avg_co2': np.mean([m['co2'] for m in rl_metrics]),\n",
    "        'total_cost': sum([m['cost'] for m in rl_metrics]),\n",
    "        'total_co2': sum([m['co2'] for m in rl_metrics]),\n",
    "        'avg_renewable_percentage': np.mean([m['renewable_percentage'] for m in rl_metrics])\n",
    "    }\n",
    "    \n",
    "    grid_only_summary = {\n",
    "        'demand_met_count': sum(1 for m in grid_only_metrics if m['demand_met']),\n",
    "        'avg_excess': np.mean([m['excess_energy'] for m in grid_only_metrics]),\n",
    "        'avg_renewable': np.mean([m['renewable_energy'] for m in grid_only_metrics]),\n",
    "        'avg_grid': np.mean([m['grid_energy'] for m in grid_only_metrics]),\n",
    "        'avg_cost': np.mean([m['cost'] for m in grid_only_metrics]),\n",
    "        'avg_co2': np.mean([m['co2'] for m in grid_only_metrics]),\n",
    "        'total_cost': sum([m['cost'] for m in grid_only_metrics]),\n",
    "        'total_co2': sum([m['co2'] for m in grid_only_metrics]),\n",
    "        'avg_renewable_percentage': np.mean([m['renewable_percentage'] for m in grid_only_metrics])\n",
    "    }\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n=== SUMMARY STATISTICS ===\\n\")\n",
    "    \n",
    "    print(\"RL Agent:\")\n",
    "    print(f\"  Demand met in {rl_summary['demand_met_count']} out of {len(test_states)} states ({rl_summary['demand_met_count']/len(test_states)*100:.1f}%)\")\n",
    "    print(f\"  Average excess energy: {rl_summary['avg_excess']:.2f}\")\n",
    "    print(f\"  Average renewable energy: {rl_summary['avg_renewable']:.2f}\")\n",
    "    print(f\"  Average grid energy: {rl_summary['avg_grid']:.2f}\")\n",
    "    print(f\"  Renewable percentage: {rl_summary['avg_renewable_percentage']:.1f}%\")\n",
    "    print(f\"  Average cost: ${rl_summary['avg_cost']:.2f}\")\n",
    "    print(f\"  Total cost: ${rl_summary['total_cost']:.2f}\")\n",
    "    print(f\"  Average CO2 emissions: {rl_summary['avg_co2']:.2f} kg\")\n",
    "    print(f\"  Total CO2 emissions: {rl_summary['total_co2']:.2f} kg\")\n",
    "    \n",
    "    print(\"\\nGrid-Only Strategy:\")\n",
    "    print(f\"  Demand met in {grid_only_summary['demand_met_count']} out of {len(test_states)} states ({grid_only_summary['demand_met_count']/len(test_states)*100:.1f}%)\")\n",
    "    print(f\"  Average excess energy: {grid_only_summary['avg_excess']:.2f}\")\n",
    "    print(f\"  Average renewable energy: {grid_only_summary['avg_renewable']:.2f}\")\n",
    "    print(f\"  Average grid energy: {grid_only_summary['avg_grid']:.2f}\")\n",
    "    print(f\"  Renewable percentage: {grid_only_summary['avg_renewable_percentage']:.1f}%\")\n",
    "    print(f\"  Average cost: ${grid_only_summary['avg_cost']:.2f}\")\n",
    "    print(f\"  Total cost: ${grid_only_summary['total_cost']:.2f}\")\n",
    "    print(f\"  Average CO2 emissions: {grid_only_summary['avg_co2']:.2f} kg\")\n",
    "    print(f\"  Total CO2 emissions: {grid_only_summary['total_co2']:.2f} kg\")\n",
    "    \n",
    "    # Calculate improvement metrics\n",
    "    improvement = {\n",
    "        'demand_met': (rl_summary['demand_met_count'] - grid_only_summary['demand_met_count']) / len(test_states) * 100,\n",
    "        'excess_energy': 0,  # Grid-only should have no excess\n",
    "        'renewable_percentage': rl_summary['avg_renewable_percentage'] - grid_only_summary['avg_renewable_percentage'],\n",
    "        'grid_reduction': ((grid_only_summary['avg_grid'] - rl_summary['avg_grid']) / grid_only_summary['avg_grid'] * 100),\n",
    "        'cost_reduction': ((grid_only_summary['avg_cost'] - rl_summary['avg_cost']) / grid_only_summary['avg_cost'] * 100),\n",
    "        'co2_reduction': ((grid_only_summary['avg_co2'] - rl_summary['avg_co2']) / grid_only_summary['avg_co2'] * 100)\n",
    "    }\n",
    "    \n",
    "    # Print improvement analysis\n",
    "    print(\"\\n=== IMPROVEMENT ANALYSIS ===\\n\")\n",
    "    print(f\"Demand satisfaction: {'+' if improvement['demand_met'] >= 0 else ''}{improvement['demand_met']:.1f}% difference\")\n",
    "    print(f\"Renewable utilization: {'+' if improvement['renewable_percentage'] >= 0 else ''}{improvement['renewable_percentage']:.1f}% difference\")\n",
    "    print(f\"Grid energy reduction: {'+' if improvement['grid_reduction'] >= 0 else ''}{improvement['grid_reduction']:.1f}%\")\n",
    "    print(f\"Cost reduction: {'+' if improvement['cost_reduction'] >= 0 else ''}{improvement['cost_reduction']:.1f}%\")\n",
    "    print(f\"CO2 emissions reduction: {'+' if improvement['co2_reduction'] >= 0 else ''}{improvement['co2_reduction']:.1f}%\")\n",
    "\n",
    "    # Create visualizations\n",
    "    create_rl_vs_grid_visualizations(rl_metrics, grid_only_metrics, rl_summary, grid_only_summary)\n",
    "    \n",
    "    return {\n",
    "        'rl_metrics': rl_metrics,\n",
    "        'grid_only_metrics': grid_only_metrics,\n",
    "        'rl_summary': rl_summary,\n",
    "        'grid_only_summary': grid_only_summary,\n",
    "        'improvement': improvement\n",
    "    }\n",
    "\n",
    "def create_rl_vs_grid_visualizations(rl_metrics, grid_only_metrics, rl_summary, grid_only_summary):\n",
    "    \"\"\"\n",
    "    Create visualizations comparing the RL agent and grid-only strategy.\n",
    "    \n",
    "    Parameters:\n",
    "    - rl_metrics: List of dictionaries with RL agent metrics\n",
    "    - grid_only_metrics: List of dictionaries with grid-only strategy metrics\n",
    "    - rl_summary: Dictionary with RL agent summary statistics\n",
    "    - grid_only_summary: Dictionary with grid-only strategy summary statistics\n",
    "    \"\"\"\n",
    "    # Set up a clean aesthetic for plots\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.rcParams.update({\n",
    "        'figure.figsize': (12, 8),\n",
    "        'font.size': 12,\n",
    "        'axes.titlesize': 16,\n",
    "        'axes.labelsize': 14\n",
    "    })\n",
    "    \n",
    "    # Visualization 1: Energy Composition Bar Chart\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Prepare data for energy composition\n",
    "    states = [i+1 for i in range(len(rl_metrics))]\n",
    "    \n",
    "    # Plot 1: Energy Composition for RL Agent and Grid-Only Strategy\n",
    "    plt.subplot(2, 2, 1)\n",
    "    \n",
    "    # Extract data for plotting\n",
    "    rl_renewable = [m['renewable_energy'] for m in rl_metrics]\n",
    "    rl_grid = [m['grid_energy'] for m in rl_metrics]\n",
    "    grid_only_renewable = [m['renewable_energy'] for m in grid_only_metrics]  # All zeros\n",
    "    grid_only_grid = [m['grid_energy'] for m in grid_only_metrics]  # All equal to demand\n",
    "    \n",
    "    # Create the grouped bar chart\n",
    "    x = np.arange(len(states))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, rl_renewable, width, label='RL Renewable', color='#2ca02c')\n",
    "    plt.bar(x - width/2, rl_grid, width, bottom=rl_renewable, label='RL Grid', color='#d62728')\n",
    "    plt.bar(x + width/2, grid_only_renewable, width, label='Grid-Only Renewable', color='#1f77b4')\n",
    "    plt.bar(x + width/2, grid_only_grid, width, bottom=grid_only_renewable, label='Grid-Only Grid', color='#ff7f0e')\n",
    "    \n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('Energy (kW)')\n",
    "    plt.title('Energy Composition by State')\n",
    "    plt.xticks(x, states)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot 2: Cost Comparison\n",
    "    plt.subplot(2, 2, 2)\n",
    "    \n",
    "    # Extract cost data\n",
    "    rl_costs = [m['cost'] for m in rl_metrics]\n",
    "    grid_only_costs = [m['cost'] for m in grid_only_metrics]\n",
    "    \n",
    "    plt.bar(x - width/2, rl_costs, width, label='RL Agent', color='#2ca02c')\n",
    "    plt.bar(x + width/2, grid_only_costs, width, label='Grid-Only Strategy', color='#1f77b4')\n",
    "    \n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('Cost ($)')\n",
    "    plt.title('Cost Comparison by State')\n",
    "    plt.xticks(x, states)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot 3: CO2 Emissions Comparison\n",
    "    plt.subplot(2, 2, 3)\n",
    "    \n",
    "    # Extract CO2 data\n",
    "    rl_co2 = [m['co2'] for m in rl_metrics]\n",
    "    grid_only_co2 = [m['co2'] for m in grid_only_metrics]\n",
    "    \n",
    "    plt.bar(x - width/2, rl_co2, width, label='RL Agent', color='#2ca02c')\n",
    "    plt.bar(x + width/2, grid_only_co2, width, label='Grid-Only Strategy', color='#1f77b4')\n",
    "    \n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('CO2 Emissions (kg)')\n",
    "    plt.title('CO2 Emissions Comparison by State')\n",
    "    plt.xticks(x, states)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot 4: Renewable Percentage Comparison\n",
    "    plt.subplot(2, 2, 4)\n",
    "    \n",
    "    # Extract renewable percentage data\n",
    "    rl_renewable_pct = [m['renewable_percentage'] for m in rl_metrics]\n",
    "    grid_only_renewable_pct = [m['renewable_percentage'] for m in grid_only_metrics]  # All zeros\n",
    "    \n",
    "    plt.bar(x - width/2, rl_renewable_pct, width, label='RL Agent', color='#2ca02c')\n",
    "    plt.bar(x + width/2, grid_only_renewable_pct, width, label='Grid-Only Strategy', color='#1f77b4')\n",
    "    \n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('Renewable Percentage (%)')\n",
    "    plt.title('Renewable Energy Percentage by State')\n",
    "    plt.xticks(x, states)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('energy_state_comparison_vs_grid_only.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Visualization 2: Summary Statistics\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Summary metrics to plot\n",
    "    metrics = ['avg_renewable', 'avg_grid', 'avg_cost', 'avg_co2']\n",
    "    metric_labels = ['Avg. Renewable Energy (kW)', 'Avg. Grid Energy (kW)', 'Avg. Cost ($)', 'Avg. CO2 Emissions (kg)']\n",
    "    \n",
    "    for i, (metric, label) in enumerate(zip(metrics, metric_labels)):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        \n",
    "        # Extract data\n",
    "        rl_value = rl_summary[metric]\n",
    "        grid_only_value = grid_only_summary[metric]\n",
    "        \n",
    "        # Create bar chart\n",
    "        plt.bar(['RL Agent', 'Grid-Only Strategy'], [rl_value, grid_only_value], color=['#2ca02c', '#1f77b4'])\n",
    "        \n",
    "        plt.ylabel(label)\n",
    "        plt.title(f'{label} Comparison')\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for j, v in enumerate([rl_value, grid_only_value]):\n",
    "            plt.text(j, v, f'{v:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('summary_comparison_vs_grid_only.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Visualization 3: Improvement Analysis\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Prepare improvement data\n",
    "    improvement_metrics = [\n",
    "        'demand_met', 'renewable_percentage', \n",
    "        'grid_reduction', 'cost_reduction', 'co2_reduction'\n",
    "    ]\n",
    "    metric_labels = [\n",
    "        'Demand Met (%)', 'Renewable % Increase', \n",
    "        'Grid Energy Reduction (%)', 'Cost Reduction (%)', 'CO2 Reduction (%)'\n",
    "    ]\n",
    "    \n",
    "    # Extract improvement values\n",
    "    improvements = [\n",
    "        (rl_summary['demand_met_count'] - grid_only_summary['demand_met_count']) / len(rl_metrics) * 100,\n",
    "        rl_summary['avg_renewable_percentage'] - grid_only_summary['avg_renewable_percentage'],\n",
    "        ((grid_only_summary['avg_grid'] - rl_summary['avg_grid']) / grid_only_summary['avg_grid'] * 100),\n",
    "        ((grid_only_summary['avg_cost'] - rl_summary['avg_cost']) / grid_only_summary['avg_cost'] * 100),\n",
    "        ((grid_only_summary['avg_co2'] - rl_summary['avg_co2']) / grid_only_summary['avg_co2'] * 100)\n",
    "    ]\n",
    "    \n",
    "    # Create bar chart of improvements\n",
    "    colors = ['#2ca02c' if i >= 0 else '#d62728' for i in improvements]\n",
    "    plt.bar(metric_labels, improvements, color=colors)\n",
    "    \n",
    "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "    plt.ylabel('Improvement (%)')\n",
    "    plt.title('RL Agent Improvement over Grid-Only Strategy')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(improvements):\n",
    "        plt.text(i, v, f'{v:.1f}%', ha='center', va='bottom' if v >= 0 else 'top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('improvement_analysis_vs_grid_only.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Visualization 4: Demand vs Energy Source\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # For each state, plot the demand and energy sources for both agents\n",
    "    demands = [m['demand'] for m in rl_metrics]\n",
    "    rl_solar = [m['pv_energy'] for m in rl_metrics]\n",
    "    rl_wind = [m['wt_energy'] for m in rl_metrics]\n",
    "    rl_grid = [m['grid_energy'] for m in rl_metrics]\n",
    "    grid_only_grid = [m['grid_energy'] for m in grid_only_metrics]\n",
    "    \n",
    "    # Plot demand as a line\n",
    "    plt.plot(states, demands, 'k-', label='Demand', linewidth=2)\n",
    "    \n",
    "    # Plot stacked bar for RL agent\n",
    "    width = 0.35\n",
    "    plt.bar([x - width/2 for x in states], rl_solar, width, label='RL Solar', color='#f4d03f')\n",
    "    plt.bar([x - width/2 for x in states], rl_wind, width, bottom=rl_solar, label='RL Wind', color='#5dade2')\n",
    "    plt.bar([x - width/2 for x in states], rl_grid, width, bottom=[s+w for s,w in zip(rl_solar, rl_wind)], label='RL Grid', color='#cb4335')\n",
    "    \n",
    "    # Plot bar for grid-only agent\n",
    "    plt.bar([x + width/2 for x in states], grid_only_grid, width, label='Grid-Only', color='#ff7f0e')\n",
    "    \n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('Energy (kW)')\n",
    "    plt.title('Demand vs Energy Source by State')\n",
    "    plt.xticks(states)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('demand_vs_energy_source.png')\n",
    "    plt.close()\n",
    "\n",
    "# Example usage:\n",
    "results = compare_rl_vs_grid_only(agent, test_states, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b1eff-8057-4a63-b933-bf6cca967973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
